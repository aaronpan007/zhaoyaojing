#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
RAGæŸ¥è¯¢æœåŠ¡æ¨¡å— (Cloudflare R2ç‰ˆæœ¬)
ä¸ºåç«¯APIæä¾›æ™ºèƒ½çŸ¥è¯†åº“æŸ¥è¯¢åŠŸèƒ½
ä½¿ç”¨Cloudflare R2äº‘å­˜å‚¨ä»£æ›¿æœ¬åœ°storage
"""

# ä¼˜å…ˆåŠ è½½ç¯å¢ƒå˜é‡ - å¿…é¡»åœ¨æ‰€æœ‰å…¶ä»–ä»£ç ä¹‹å‰
from dotenv import load_dotenv
load_dotenv()

import os
import sys
import json
import logging
from pathlib import Path
from typing import List, Dict, Any

# å®Œå…¨ç¦ç”¨æ‰€æœ‰å¯èƒ½çš„è¾“å‡ºåˆ°stdout
import warnings
warnings.filterwarnings('ignore')

# é‡å®šå‘æ‰€æœ‰å¯èƒ½çš„è¾“å‡ºåˆ°null
class DevNull:
    def write(self, msg):
        pass
    def flush(self):
        pass

# åœ¨å¯¼å…¥LlamaIndexä¹‹å‰ï¼Œå…ˆè®¾ç½®ç¯å¢ƒå˜é‡ç¦ç”¨verboseè¾“å‡º
os.environ["LLAMA_INDEX_LOGGING_LEVEL"] = "CRITICAL"
os.environ["TOKENIZERS_PARALLELISM"] = "false"

# ä¸´æ—¶é‡å®šå‘stdoutï¼Œé˜²æ­¢LlamaIndexçš„å¯¼å…¥æ—¶è¾“å‡º
original_stdout = sys.stdout
sys.stdout = DevNull()

try:
    # LlamaIndexæ ¸å¿ƒæ¨¡å—
    from llama_index.core import (
        StorageContext,
        load_index_from_storage,
        Settings,
        VectorStoreIndex
    )
    from llama_index.embeddings.openai import OpenAIEmbedding
    from llama_index.core.llms import MockLLM
    
    # S3å…¼å®¹å­˜å‚¨æ¨¡å—
    from llama_index.storage.kvstore.s3 import S3DBKVStore
    from llama_index.storage.docstore.s3 import S3DocumentStore
    from llama_index.vector_stores.simple import SimpleVectorStore
    
    # S3FSæ–‡ä»¶ç³»ç»Ÿï¼ˆS3å…¼å®¹ï¼‰
    import s3fs
    
finally:
    # æ¢å¤stdout
    sys.stdout = original_stdout

# é…ç½®æ—¥å¿—ï¼Œé‡å®šå‘åˆ°stderré¿å…æ±¡æŸ“stdout
logging.basicConfig(
    level=logging.CRITICAL,  # åªè¾“å‡ºä¸¥é‡é”™è¯¯
    stream=sys.stderr,       # é‡å®šå‘åˆ°stderr
    format='%(message)s'
)
logger = logging.getLogger(__name__)

class RAGR2QueryService:
    """RAGæŸ¥è¯¢æœåŠ¡ç±» - Cloudflare R2ç‰ˆæœ¬"""
    
    def __init__(self):
        """
        åˆå§‹åŒ–RAGæŸ¥è¯¢æœåŠ¡ - ä½¿ç”¨Cloudflare R2äº‘å­˜å‚¨
        """
        self.index = None
        self.query_engine = None
        self.s3fs = None
        
        # åˆå§‹åŒ–çŠ¶æ€
        self.is_initialized = False
        self.initialization_error = None
        
        try:
            # éªŒè¯R2é…ç½®
            self._validate_r2_config()
            
            # é…ç½®LlamaIndexè®¾ç½®
            self._setup_llama_index()
            
            # åˆå§‹åŒ–S3FSæ–‡ä»¶ç³»ç»Ÿ
            self._setup_s3fs()
            
            # åŠ è½½ç´¢å¼•
            if self.load_index_from_r2():
                self.is_initialized = True
            else:
                self.initialization_error = "ä»R2åŠ è½½ç´¢å¼•å¤±è´¥"
                
        except Exception as e:
            self.initialization_error = str(e)
            logger.error(f"RAGç³»ç»Ÿåˆå§‹åŒ–å¤±è´¥: {str(e)}")
    
    def _validate_r2_config(self):
        """éªŒè¯Cloudflare R2é…ç½®"""
        required_vars = [
            "CLOUDFLARE_ACCOUNT_ID",
            "R2_ACCESS_KEY_ID", 
            "R2_SECRET_ACCESS_KEY",
            "BUCKET_NAME"
        ]
        
        missing_vars = []
        for var in required_vars:
            if not os.getenv(var):
                missing_vars.append(var)
        
        if missing_vars:
            raise ValueError(f"ç¼ºå°‘å¿…éœ€çš„ç¯å¢ƒå˜é‡: {', '.join(missing_vars)}")
        
        logger.debug("R2é…ç½®éªŒè¯é€šè¿‡")
    
    def _setup_llama_index(self):
        """é…ç½®LlamaIndexå…¨å±€è®¾ç½® - ä½¿ç”¨OpenAI"""
        
        # æ£€æŸ¥OpenAI APIå¯†é’¥
        openai_api_key = os.getenv("OPENAI_API_KEY")
        if not openai_api_key:
            raise ValueError("æœªæ‰¾åˆ°OPENAI_API_KEYç¯å¢ƒå˜é‡ï¼è¯·åœ¨.envæ–‡ä»¶ä¸­é…ç½®æ‚¨çš„OpenAI APIå¯†é’¥")
        
        # è·å–OpenAI APIåŸºç¡€URL
        openai_api_base = os.getenv("OPENAI_API_BASE", "https://api.openai.com/v1")
        
        # ä½¿ç”¨OpenAI embedding
        Settings.embed_model = OpenAIEmbedding(
            model="text-embedding-3-small",
            api_key=openai_api_key,
            api_base=openai_api_base
        )
        
        # ä½¿ç”¨MockLLMé¿å…LLMè°ƒç”¨ï¼ŒåŒæ—¶è®¾ç½®æå…¶ä¿å®ˆçš„å‚æ•°
        Settings.llm = MockLLM(max_tokens=128)
        
        # è®¾ç½®æå…¶ä¿å®ˆçš„ä¸Šä¸‹æ–‡å‚æ•°é¿å…è¶…å‡ºé™åˆ¶
        Settings.chunk_size = 128    # æå°çš„chunk size
        Settings.chunk_overlap = 20   # æå°çš„overlap
        Settings.context_window = 512 # æå°çš„ä¸Šä¸‹æ–‡çª—å£
        Settings.num_output = 64      # æå°çš„è¾“å‡ºé•¿åº¦
        
        logger.debug("LlamaIndexé…ç½®å®Œæˆ (OpenAI Embedding)")
    
    def _setup_s3fs(self):
        """åˆå§‹åŒ–S3FSæ–‡ä»¶ç³»ç»Ÿè¿æ¥R2"""
        account_id = os.getenv("CLOUDFLARE_ACCOUNT_ID")
        access_key = os.getenv("R2_ACCESS_KEY_ID")
        secret_key = os.getenv("R2_SECRET_ACCESS_KEY")
        
        # Cloudflare R2çš„endpoint URLæ ¼å¼
        endpoint_url = f"https://{account_id}.r2.cloudflarestorage.com"
        
        try:
            self.s3fs = s3fs.S3FileSystem(
                key=access_key,
                secret=secret_key,
                endpoint_url=endpoint_url,
                use_ssl=True
            )
            
            # æµ‹è¯•è¿æ¥
            bucket_name = os.getenv("BUCKET_NAME")
            if not self.s3fs.exists(bucket_name):
                raise ValueError(f"R2å­˜å‚¨æ¡¶ä¸å­˜åœ¨æˆ–æ— æ³•è®¿é—®: {bucket_name}")
            
            logger.debug(f"S3FSè¿æ¥åˆ°R2æˆåŠŸ: {endpoint_url}")
            
        except Exception as e:
            raise ValueError(f"è¿æ¥Cloudflare R2å¤±è´¥: {str(e)}")
    
    def load_index_from_r2(self):
        """ä»Cloudflare R2åŠ è½½ç´¢å¼•"""
        try:
            bucket_name = os.getenv("BUCKET_NAME")
            
            # æ£€æŸ¥å¿…éœ€çš„ç´¢å¼•æ–‡ä»¶æ˜¯å¦å­˜åœ¨
            required_files = [
                f"{bucket_name}/index_store.json",
                f"{bucket_name}/default__vector_store.json",
                f"{bucket_name}/docstore.json"
            ]
            
            for file_path in required_files:
                if not self.s3fs.exists(file_path):
                    logger.error(f"R2ä¸­æœªæ‰¾åˆ°å¿…éœ€æ–‡ä»¶: {file_path}")
                    return False
            
            # ä¸´æ—¶é‡å®šå‘stdoutï¼Œé˜²æ­¢loadingä¿¡æ¯è¾“å‡º
            original_stdout = sys.stdout
            sys.stdout = DevNull()
            
            try:
                # é…ç½®S3å…¼å®¹çš„å­˜å‚¨ä¸Šä¸‹æ–‡
                account_id = os.getenv("CLOUDFLARE_ACCOUNT_ID")
                access_key = os.getenv("R2_ACCESS_KEY_ID")
                secret_key = os.getenv("R2_SECRET_ACCESS_KEY")
                endpoint_url = f"https://{account_id}.r2.cloudflarestorage.com"
                
                # åˆ›å»ºåŸºäºR2çš„KVå­˜å‚¨
                kv_store = S3DBKVStore(
                    s3_bucket=bucket_name,
                    aws_access_key_id=access_key,
                    aws_secret_access_key=secret_key,
                    aws_endpoint_url=endpoint_url
                )
                
                # åˆ›å»ºåŸºäºR2çš„æ–‡æ¡£å­˜å‚¨
                docstore = S3DocumentStore(
                    s3_bucket=bucket_name,
                    aws_access_key_id=access_key,
                    aws_secret_access_key=secret_key,
                    aws_endpoint_url=endpoint_url
                )
                
                # åˆ›å»ºå­˜å‚¨ä¸Šä¸‹æ–‡
                storage_context = StorageContext.from_defaults(
                    docstore=docstore,
                    index_store=kv_store,
                    vector_store=SimpleVectorStore()  # ä½¿ç”¨ç®€å•å‘é‡å­˜å‚¨
                )
                
                # ä»R2å­˜å‚¨ä¸­åŠ è½½ç´¢å¼•
                self.index = load_index_from_storage(storage_context)
                
                # åˆ›å»ºæŸ¥è¯¢å¼•æ“ - ä½¿ç”¨æœ€æœ€ä¿å®ˆçš„è®¾ç½®é¿å…ä¸Šä¸‹æ–‡é—®é¢˜
                self.query_engine = self.index.as_query_engine(
                    similarity_top_k=5,         # ä¼˜åŒ–ï¼šå–5ä¸ªæœ€ç›¸å…³çš„æ–‡æ¡£ç‰‡æ®µï¼Œæå‡çŸ¥è¯†åº“è¦†ç›–åº¦
                    response_mode="compact",    # ä½¿ç”¨compactæ¨¡å¼
                    text_qa_template=None,      # ä¸ä½¿ç”¨æ¨¡æ¿
                    streaming=False,
                    verbose=False               # ç¦ç”¨verboseè¾“å‡º
                )
                
                logger.debug("ä»R2æˆåŠŸåŠ è½½RAGç´¢å¼•")
                
            finally:
                # æ¢å¤stdout
                sys.stdout = original_stdout
            
            return True
            
        except Exception as e:
            logger.error(f"ä»R2åŠ è½½ç´¢å¼•å¤±è´¥: {str(e)}")
            return False
    
    def query(self, question: str, context: str = "", diagnostic_mode: bool = False) -> Dict[str, Any]:
        """
        æ‰§è¡ŒRAGæŸ¥è¯¢
        
        Args:
            question: æŸ¥è¯¢é—®é¢˜
            context: é¢å¤–ä¸Šä¸‹æ–‡
            diagnostic_mode: æ˜¯å¦å¯ç”¨è¯Šæ–­æ¨¡å¼ï¼Œè¾“å‡ºè¯¦ç»†æ£€ç´¢ä¿¡æ¯åˆ°stderr
            
        Returns:
            æŸ¥è¯¢ç»“æœå­—å…¸
        """
        if not self.is_initialized:
            return {
                "error": f"RAGç³»ç»Ÿæœªåˆå§‹åŒ–: {self.initialization_error}",
                "answer": "",
                "sources": [],
                "query": question,
                "context": context,
                "sources_count": 0
            }
        
        try:
            # æ„å»ºæŸ¥è¯¢ - æˆªæ–­è¿‡é•¿çš„å†…å®¹é¿å…ä¸Šä¸‹æ–‡è¶…é™
            if len(question) > 100:
                question = question[:100] + "..."
            
            if context and len(context) > 50:
                context = context[:50] + "..."
            
            full_query = f"{question}\n{context}" if context else question
            
            # ä¸´æ—¶é‡å®šå‘stdoutï¼Œé˜²æ­¢æŸ¥è¯¢è¿‡ç¨‹çš„è¾“å‡º
            original_stdout = sys.stdout
            sys.stdout = DevNull()
            
            try:
                # æ‰§è¡ŒæŸ¥è¯¢
                response = self.query_engine.query(full_query)
            finally:
                # æ¢å¤stdout
                sys.stdout = original_stdout
            
            # æå–æºä¿¡æ¯
            sources = []
            if hasattr(response, 'source_nodes'):
                # ğŸ” è¯Šæ–­æ¨¡å¼ï¼šè¯¦ç»†è¾“å‡ºæ£€ç´¢ä¿¡æ¯åˆ°stderr
                if diagnostic_mode:
                    logger.info(f"ğŸ” æ£€ç´¢åˆ° {len(response.source_nodes)} ä¸ªç›¸å…³æ–‡æ¡£ç‰‡æ®µ:")
                
                for i, node in enumerate(response.source_nodes):
                    similarity_score = getattr(node, 'score', 0.0)
                    
                    # è·å–å…ƒæ•°æ®
                    metadata = getattr(node.node, 'metadata', {})
                    file_name = metadata.get('file_name', 'unknown')
                    file_path = metadata.get('file_path', '')
                    
                    # æˆªæ–­æ–‡æœ¬å†…å®¹è¿›è¡Œé¢„è§ˆ
                    text_preview = node.node.text[:200] + "..." if len(node.node.text) > 200 else node.node.text
                    
                    source_info = {
                        "file_name": file_name,
                        "file_path": file_path,
                        "similarity_score": round(similarity_score, 3),
                        "text_preview": text_preview,
                        "node_id": node.node.node_id
                    }
                    
                    sources.append(source_info)
                    
                    # ğŸ” è¯Šæ–­æ¨¡å¼ï¼šè¾“å‡ºè¯¦ç»†ä¿¡æ¯åˆ°stderr
                    if diagnostic_mode:
                        logger.info(f"  ğŸ“„ ç‰‡æ®µ {i+1}: {file_name}")
                        logger.info(f"     ç›¸ä¼¼åº¦: {similarity_score:.3f}")
                        logger.info(f"     é¢„è§ˆ: {text_preview[:100]}...")
                        logger.info("")
            
            # ğŸ” è¯Šæ–­æ¨¡å¼ï¼šè¾“å‡ºæœ€ç»ˆç­”æ¡ˆåˆ°stderr
            if diagnostic_mode:
                logger.info(f"ğŸ¯ RAGç³»ç»Ÿè¿”å›ç­”æ¡ˆ:")
                logger.info(f"   æŸ¥è¯¢: {question}")
                logger.info(f"   ç­”æ¡ˆ: {str(response)[:200]}...")
                logger.info(f"   ä½¿ç”¨æºæ•°é‡: {len(sources)}")
                logger.info("=" * 50)
            
            return {
                "answer": str(response),
                "sources": sources,
                "query": question,
                "context": context,
                "sources_count": len(sources),
                "storage_type": "cloudflare_r2"
            }
            
        except Exception as e:
            logger.error(f"RAGæŸ¥è¯¢å¤±è´¥: {str(e)}")
            return {
                "error": f"æŸ¥è¯¢å¤±è´¥: {str(e)}",
                "answer": "",
                "sources": [],
                "query": question,
                "context": context,
                "sources_count": 0
            }

def create_rag_query(user_input: dict, image_analysis: list) -> str:
    """
    æ ¹æ®ç”¨æˆ·è¾“å…¥å’Œå›¾ç‰‡åˆ†æç»“æœåˆ›å»ºRAGæŸ¥è¯¢å­—ç¬¦ä¸²
    """
    query_parts = []
    
    if user_input.get('nickname'):
        query_parts.append(f"åˆ†æå¯¹è±¡æ˜µç§°: {user_input['nickname']}")
    
    if user_input.get('profession'):
        query_parts.append(f"èŒä¸š: {user_input['profession']}")
    
    if user_input.get('age'):
        query_parts.append(f"å¹´é¾„: {user_input['age']}")
    
    if user_input.get('bioOrChatHistory'):
        query_parts.append(f"ä¸ªäººç®€ä»‹æˆ–èŠå¤©è®°å½•: {user_input['bioOrChatHistory']}")
    
    if image_analysis:
        query_parts.append("å›¾ç‰‡åˆ†æç»“æœ:")
        for i, analysis in enumerate(image_analysis):
            query_parts.append(f"å›¾ç‰‡{i+1}: {analysis.get('analysis', '')}")
    
    return " ".join(query_parts)

def generate_final_report(rag_result: dict, user_input: dict, image_analysis: list) -> dict:
    """
    åŸºäºRAGæŸ¥è¯¢ç»“æœç”Ÿæˆæœ€ç»ˆåˆ†ææŠ¥å‘Š
    """
    try:
        # åŸºç¡€æŠ¥å‘Šç»“æ„
        report = {
            "risk_level": "unknown",
            "key_findings": {},
            "final_suggestion": "",
            "confidence_level": "medium",
            "professional_insight": "",
            "analysis_metadata": {
                "processed_images": len(image_analysis),
                "analysis_timestamp": "",
                "processing_time": "",
                "rag_sources_count": rag_result.get("sources_count", 0),
                "storage_type": rag_result.get("storage_type", "cloudflare_r2")
            }
        }
        
        # å¦‚æœRAGæŸ¥è¯¢æˆåŠŸï¼Œä½¿ç”¨è¿”å›çš„åˆ†æ
        if rag_result.get("answer") and not rag_result.get("error"):
            # ç®€å•çš„é£é™©ç­‰çº§åˆ¤æ–­é€»è¾‘
            answer_text = rag_result["answer"].lower()
            
            if any(word in answer_text for word in ["é«˜é£é™©", "å±é™©", "è­¦å‘Š", "ä¸å»ºè®®"]):
                report["risk_level"] = "high"
            elif any(word in answer_text for word in ["ä¸­ç­‰é£é™©", "è°¨æ…", "æ³¨æ„"]):
                report["risk_level"] = "medium"
            elif any(word in answer_text for word in ["ä½é£é™©", "å®‰å…¨", "å¯ä»¥"]):
                report["risk_level"] = "low"
            else:
                report["risk_level"] = "medium"
            
            # è®¾ç½®ä¸»è¦å‘ç°å’Œå»ºè®®
            report["professional_insight"] = rag_result["answer"]
            report["final_suggestion"] = "åŸºäºä¸“ä¸šçŸ¥è¯†åº“åˆ†æï¼Œè¯·å‚è€ƒä¸Šè¿°è¯¦ç»†åˆ†æã€‚"
            
            # è®¾ç½®å…³é”®å‘ç°
            if rag_result.get("sources"):
                report["key_findings"]["knowledge_sources"] = f"å¼•ç”¨äº†{len(rag_result['sources'])}ä¸ªä¸“ä¸šèµ„æ–™"
            
        else:
            # RAGæŸ¥è¯¢å¤±è´¥çš„åå¤‡æ–¹æ¡ˆ
            report["professional_insight"] = "ç”±äºçŸ¥è¯†åº“æŸ¥è¯¢å¤±è´¥ï¼Œæ— æ³•æä¾›ä¸“ä¸šåˆ†æã€‚å»ºè®®æ‰‹åŠ¨è¯„ä¼°ã€‚"
            report["final_suggestion"] = "å»ºè®®å¯»æ±‚ä¸“ä¸šäººå£«æ„è§ã€‚"
            report["risk_level"] = "unknown"
        
        return report
        
    except Exception as e:
        logger.error(f"ç”Ÿæˆæœ€ç»ˆæŠ¥å‘Šå¤±è´¥: {str(e)}")
        return {
            "risk_level": "unknown",
            "key_findings": {"error": "æŠ¥å‘Šç”Ÿæˆå¤±è´¥"},
            "final_suggestion": "ç³»ç»Ÿå‡ºé”™ï¼Œè¯·ç¨åé‡è¯•ã€‚",
            "confidence_level": "low",
            "professional_insight": f"æŠ¥å‘Šç”Ÿæˆå‡ºé”™: {str(e)}",
            "analysis_metadata": {
                "processed_images": len(image_analysis),
                "analysis_timestamp": "",
                "processing_time": "",
                "error": str(e)
            }
        }

def main():
    """æµ‹è¯•å‡½æ•°"""
    print("æµ‹è¯•RAG R2æŸ¥è¯¢æœåŠ¡...")
    
    # åˆ›å»ºæœåŠ¡å®ä¾‹
    service = RAGR2QueryService()
    
    if not service.is_initialized:
        print(f"æœåŠ¡åˆå§‹åŒ–å¤±è´¥: {service.initialization_error}")
        return
    
    print("æœåŠ¡åˆå§‹åŒ–æˆåŠŸï¼")
    
    # æµ‹è¯•æŸ¥è¯¢
    test_query = "å¦‚ä½•è¯†åˆ«çº¦ä¼šä¸­çš„çº¢æ——ä¿¡å·ï¼Ÿ"
    result = service.query(test_query, diagnostic_mode=True)
    
    print(f"æŸ¥è¯¢ç»“æœ: {result}")

if __name__ == "__main__":
    main() 