#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
AIæƒ…æ„Ÿå®‰å…¨åŠ©æ‰‹ - RAGç³»ç»Ÿæ„å»ºè„šæœ¬ (OpenAIä»£ç†ç‰ˆæœ¬)
ä½¿ç”¨LlamaIndex + OpenAI API (é€šè¿‡ä»£ç†) æ„å»ºåŸºäºæœ¬åœ°çŸ¥è¯†åº“çš„æ™ºèƒ½æŸ¥è¯¢ç³»ç»Ÿ
"""

# ä¼˜å…ˆåŠ è½½ç¯å¢ƒå˜é‡ - å¿…é¡»åœ¨æ‰€æœ‰å…¶ä»–ä»£ç ä¹‹å‰
from dotenv import load_dotenv
load_dotenv()

import os
import sys
from pathlib import Path
from typing import List, Any
import logging

# ç¯å¢ƒæ£€æŸ¥ï¼šç¡®ä¿ä½¿ç”¨OpenAI APIä»£ç†
def validate_environment():
    """éªŒè¯ç¯å¢ƒé…ç½®ï¼Œç¡®ä¿OpenAI APIå¯†é’¥å¯ç”¨"""
    # æ£€æŸ¥å¿…éœ€çš„OpenAI APIå¯†é’¥
    openai_key = os.getenv("OPENAI_API_KEY")
    if not openai_key or openai_key == "your_openai_api_key_here":
        print("âŒ é”™è¯¯: æœªæ‰¾åˆ°æœ‰æ•ˆçš„OPENAI_API_KEYç¯å¢ƒå˜é‡ï¼")
        print("è¯·åœ¨.envæ–‡ä»¶ä¸­é…ç½®æ‚¨çš„OpenAI APIå¯†é’¥")
        print('æ ¼å¼: OPENAI_API_KEY="sk-your_api_key_here"')
        sys.exit(1)
    
    # è®¾ç½®OpenAIä»£ç†é…ç½®
    proxy_base_url = "https://api.gptsapi.net/v1"
    os.environ["OPENAI_API_BASE"] = proxy_base_url
    
    print("âœ… ç¯å¢ƒéªŒè¯é€šè¿‡ï¼Œå·²é…ç½®OpenAI APIä»£ç†")
    print(f"ğŸ”— APIä»£ç†åœ°å€: {proxy_base_url}")
    return openai_key, proxy_base_url

# æ‰§è¡Œç¯å¢ƒéªŒè¯
api_key, base_url = validate_environment()

# LlamaIndexæ ¸å¿ƒæ¨¡å—
from llama_index.core import (
    VectorStoreIndex, 
    SimpleDirectoryReader, 
    StorageContext,
    load_index_from_storage,
    Settings
)
from llama_index.embeddings.openai import OpenAIEmbedding

# è®¾ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('rag_build.log', encoding='utf-8'),
        logging.StreamHandler(sys.stdout)
    ]
)
logger = logging.getLogger(__name__)

class RAGSystemBuilder:
    """RAGç³»ç»Ÿæ„å»ºå™¨ - OpenAIä»£ç†ç‰ˆæœ¬"""
    
    def __init__(self, knowledge_path: str = "my_knowledge", storage_path: str = "storage"):
        """
        åˆå§‹åŒ–RAGç³»ç»Ÿæ„å»ºå™¨
        
        Args:
            knowledge_path: çŸ¥è¯†åº“æ–‡ä»¶å¤¹è·¯å¾„
            storage_path: ç´¢å¼•å­˜å‚¨è·¯å¾„
        """
        self.knowledge_path = Path(knowledge_path)
        self.storage_path = Path(storage_path)
        self.index = None
        self.query_engine = None
        
        # åˆ›å»ºå­˜å‚¨ç›®å½•
        self.storage_path.mkdir(exist_ok=True)
        
        # é…ç½®LlamaIndexè®¾ç½®
        self._setup_llama_index()
    
    def _setup_llama_index(self):
        """é…ç½®LlamaIndexå…¨å±€è®¾ç½® - OpenAIä»£ç†ç‰ˆæœ¬"""
        logger.info("âš™ï¸ é…ç½®LlamaIndexå…¨å±€è®¾ç½®...")
        
        # åˆ›å»ºOpenAI Embeddingå®ä¾‹ï¼Œä½¿ç”¨ä»£ç†åœ°å€
        self.embed_model = OpenAIEmbedding(
            model="text-embedding-3-small",  # ä½¿ç”¨é«˜æ•ˆçš„embeddingæ¨¡å‹
            api_key=api_key,
            api_base="https://api.gptsapi.net/v1",  # ä½¿ç”¨æ­£ç¡®çš„ä»£ç†åœ°å€
            embed_batch_size=10,  # å‡å°‘æ‰¹å¤„ç†å¤§å°ä»¥é¿å…é€Ÿç‡é™åˆ¶
            max_retries=5  # å¢åŠ é‡è¯•æ¬¡æ•°
        )
        
        # è®¾ç½®å…¨å±€é…ç½®
        Settings.embed_model = self.embed_model
        Settings.llm = None  # æ˜ç¡®ç¦ç”¨LLMï¼ˆåœ¨åç«¯å¤„ç†ï¼‰
        Settings.chunk_size = 1024
        Settings.chunk_overlap = 100
        
        logger.info("âœ… LlamaIndexé…ç½®å®Œæˆ")
        logger.info(f"ğŸ§  Embeddingæ¨¡å‹: text-embedding-3-small")
        logger.info(f"ğŸ”— APIä»£ç†åœ°å€: {base_url}")
        logger.info("ğŸš« LLMå·²ç¦ç”¨ï¼Œå°†åœ¨åç«¯å¤„ç†")
    
    def check_knowledge_base(self) -> bool:
        """æ£€æŸ¥çŸ¥è¯†åº“æ–‡ä»¶å¤¹æ˜¯å¦å­˜åœ¨"""
        if not self.knowledge_path.exists():
            logger.error(f"âŒ çŸ¥è¯†åº“æ–‡ä»¶å¤¹ä¸å­˜åœ¨: {self.knowledge_path}")
            return False
        
        # ç»Ÿè®¡æ–‡ä»¶æ•°é‡
        supported_extensions = {'.pdf', '.txt', '.docx'}
        file_count = 0
        
        for ext in supported_extensions:
            count = len(list(self.knowledge_path.rglob(f"*{ext}")))
            if count > 0:
                logger.info(f"ğŸ“ å‘ç° {count} ä¸ª {ext} æ–‡ä»¶")
                file_count += count
        
        if file_count == 0:
            logger.error("âŒ æœªå‘ç°ä»»ä½•æ”¯æŒçš„æ–‡æ¡£æ–‡ä»¶(.pdf, .txt, .docx)")
            return False
        
        logger.info(f"âœ… çŸ¥è¯†åº“æ£€æŸ¥å®Œæˆï¼Œå…±å‘ç° {file_count} ä¸ªæ–‡æ¡£æ–‡ä»¶")
        return True
    
    def load_documents(self):
        """åŠ è½½æ‰€æœ‰æ–‡æ¡£"""
        logger.info("ğŸ“š å¼€å§‹åŠ è½½æ–‡æ¡£...")
        
        try:
            # ä½¿ç”¨SimpleDirectoryReaderé€’å½’åŠ è½½æ‰€æœ‰æ”¯æŒçš„æ–‡æ¡£
            reader = SimpleDirectoryReader(
                input_dir=str(self.knowledge_path),
                recursive=True,
                required_exts=[".pdf", ".txt", ".docx"],
                encoding="utf-8"
            )
            
            documents = reader.load_data()
            
            if not documents:
                logger.error("âŒ æœªèƒ½åŠ è½½ä»»ä½•æ–‡æ¡£ï¼")
                return None
            
            logger.info(f"âœ… æˆåŠŸåŠ è½½ {len(documents)} ä¸ªæ–‡æ¡£ç‰‡æ®µ")
            
            # æ˜¾ç¤ºæ–‡æ¡£æ¥æºç»Ÿè®¡
            sources = set()
            for doc in documents:
                if hasattr(doc, 'metadata') and 'file_path' in doc.metadata:
                    sources.add(doc.metadata['file_path'])
            
            logger.info(f"ğŸ“‚ æ–‡æ¡£æ¥æº: {len(sources)} ä¸ªä¸åŒæ–‡ä»¶")
            
            return documents
            
        except Exception as e:
            logger.error(f"âŒ æ–‡æ¡£åŠ è½½å¤±è´¥: {str(e)}")
            return None
    
    def build_index(self, documents):
        """æ„å»ºå‘é‡ç´¢å¼• - ä½¿ç”¨OpenAI Embedding"""
        logger.info("ğŸ—ï¸ å¼€å§‹æ„å»ºå‘é‡ç´¢å¼•...")
        logger.info(f"ğŸ§  ä½¿ç”¨æ¨¡å‹: text-embedding-3-small")
        logger.info(f"ğŸ”— APIä»£ç†åœ°å€: {base_url}")
        logger.info("â³ å¼€å§‹å¤„ç†æ–‡æ¡£ï¼Œè¿™å¯èƒ½éœ€è¦ä¸€äº›æ—¶é—´...")
        
        try:
            # ä½¿ç”¨OpenAI embeddingæ¨¡å‹åˆ›å»ºå‘é‡ç´¢å¼•
            self.index = VectorStoreIndex.from_documents(
                documents,
                embed_model=self.embed_model,  # æ˜ç¡®æŒ‡å®šæˆ‘ä»¬çš„embeddingæ¨¡å‹
                show_progress=True,
                use_async=False  # é¿å…å¹¶å‘é—®é¢˜
            )
            
            logger.info("ğŸ‰ å‘é‡ç´¢å¼•æ„å»ºå®Œæˆï¼")
            return True
            
        except Exception as e:
            logger.error(f"âŒ ç´¢å¼•æ„å»ºå¤±è´¥: {str(e)}")
            logger.error(f"è¯¦ç»†é”™è¯¯ä¿¡æ¯: {repr(e)}")
            return False
    
    def save_index(self):
        """æŒä¹…åŒ–ä¿å­˜ç´¢å¼•"""
        if not self.index:
            logger.error("âŒ æ²¡æœ‰å¯ä¿å­˜çš„ç´¢å¼•")
            return False
        
        logger.info("ğŸ’¾ ä¿å­˜ç´¢å¼•åˆ°æœ¬åœ°å­˜å‚¨...")
        
        try:
            # ä¿å­˜ç´¢å¼•åˆ°æŒ‡å®šç›®å½•
            self.index.storage_context.persist(persist_dir=str(self.storage_path))
            logger.info(f"âœ… ç´¢å¼•å·²ä¿å­˜åˆ°: {self.storage_path}")
            return True
            
        except Exception as e:
            logger.error(f"âŒ ç´¢å¼•ä¿å­˜å¤±è´¥: {str(e)}")
            return False
    
    def load_existing_index(self):
        """åŠ è½½å·²å­˜åœ¨çš„ç´¢å¼•"""
        if not (self.storage_path / "index_store.json").exists():
            logger.info("ğŸ“ æœªå‘ç°å·²å­˜åœ¨çš„ç´¢å¼•æ–‡ä»¶")
            return False
        
        logger.info("ğŸ“‚ åŠ è½½å·²å­˜åœ¨çš„ç´¢å¼•...")
        
        try:
            # ç¡®ä¿ä½¿ç”¨ç›¸åŒçš„embeddingæ¨¡å‹é…ç½®
            Settings.embed_model = self.embed_model
            
            # ä»å­˜å‚¨ä¸­åŠ è½½ç´¢å¼•
            storage_context = StorageContext.from_defaults(persist_dir=str(self.storage_path))
            self.index = load_index_from_storage(storage_context)
            
            logger.info("âœ… æˆåŠŸåŠ è½½å·²å­˜åœ¨çš„ç´¢å¼•")
            logger.info(f"ğŸ§  ä½¿ç”¨embeddingæ¨¡å‹: text-embedding-3-small")
            return True
            
        except Exception as e:
            logger.error(f"âŒ åŠ è½½ç´¢å¼•å¤±è´¥: {str(e)}")
            logger.error(f"è¯¦ç»†é”™è¯¯ä¿¡æ¯: {repr(e)}")
            return False
    
    def create_query_engine(self):
        """åˆ›å»ºæŸ¥è¯¢å¼•æ“"""
        if not self.index:
            logger.error("âŒ éœ€è¦å…ˆæ„å»ºæˆ–åŠ è½½ç´¢å¼•")
            return False
        
        logger.info("ğŸ” åˆ›å»ºæŸ¥è¯¢å¼•æ“...")
        
        try:
            # åˆ›å»ºæŸ¥è¯¢å¼•æ“ï¼Œé…ç½®ç›¸ä¼¼åº¦æœç´¢å‚æ•°
            self.query_engine = self.index.as_query_engine(
                similarity_top_k=5,
                response_mode="compact"
            )
            
            logger.info("âœ… æŸ¥è¯¢å¼•æ“åˆ›å»ºå®Œæˆï¼")
            return True
            
        except Exception as e:
            logger.error(f"âŒ æŸ¥è¯¢å¼•æ“åˆ›å»ºå¤±è´¥: {str(e)}")
            return False
    
    def test_query(self, test_question: str = "ä»€ä¹ˆæ˜¯çº¢è¯ä¸¸ç†è®ºï¼Ÿ"):
        """æµ‹è¯•æŸ¥è¯¢åŠŸèƒ½"""
        if not self.query_engine:
            logger.error("âŒ æŸ¥è¯¢å¼•æ“æœªå°±ç»ª")
            return
        
        logger.info(f"ğŸ§ª æµ‹è¯•æŸ¥è¯¢: {test_question}")
        
        try:
            # æ³¨æ„ï¼šè¿™é‡Œåªæµ‹è¯•æ£€ç´¢ï¼Œä¸è¿›è¡ŒLLMå›ç­”
            retriever = self.index.as_retriever(similarity_top_k=3)
            nodes = retriever.retrieve(test_question)
            
            logger.info("âœ… æŸ¥è¯¢æµ‹è¯•æˆåŠŸï¼")
            logger.info(f"ğŸ“ æ£€ç´¢åˆ° {len(nodes)} ä¸ªç›¸å…³æ–‡æ¡£ç‰‡æ®µ")
            
            for i, node in enumerate(nodes, 1):
                logger.info(f"   ğŸ“„ ç‰‡æ®µ {i}: {node.text[:100]}...")
            
        except Exception as e:
            logger.error(f"âŒ æŸ¥è¯¢æµ‹è¯•å¤±è´¥: {str(e)}")
    
    def build_complete_system(self, force_rebuild: bool = False):
        """æ„å»ºå®Œæ•´çš„RAGç³»ç»Ÿ"""
        logger.info("ğŸš€ å¼€å§‹æ„å»ºAIæƒ…æ„Ÿå®‰å…¨åŠ©æ‰‹RAGç³»ç»Ÿ (OpenAIä»£ç†ç‰ˆæœ¬)...")
        
        # 1. æ£€æŸ¥çŸ¥è¯†åº“
        if not self.check_knowledge_base():
            return False
        
        # 2. å°è¯•åŠ è½½å·²å­˜åœ¨çš„ç´¢å¼•ï¼ˆå¦‚æœä¸å¼ºåˆ¶é‡å»ºï¼‰
        if not force_rebuild and self.load_existing_index():
            logger.info("ğŸ’¡ ä½¿ç”¨å·²å­˜åœ¨çš„ç´¢å¼•ï¼Œè·³è¿‡é‡å»ºæ­¥éª¤")
        else:
            # 3. åŠ è½½æ–‡æ¡£
            documents = self.load_documents()
            if not documents:
                return False
            
            # 4. æ„å»ºç´¢å¼•
            if not self.build_index(documents):
                return False
            
            # 5. ä¿å­˜ç´¢å¼•
            if not self.save_index():
                return False
        
        # 6. åˆ›å»ºæŸ¥è¯¢å¼•æ“
        if not self.create_query_engine():
            return False
        
        # 7. æµ‹è¯•æŸ¥è¯¢
        self.test_query()
        
        logger.info("ğŸ‰ RAGç³»ç»Ÿæ„å»ºå®Œæˆï¼")
        logger.info("ğŸ“Š ç³»ç»Ÿæ‘˜è¦:")
        logger.info(f"   ğŸ§  Embeddingæ¨¡å‹: OpenAI text-embedding-3-small")
        logger.info(f"   ğŸ”— APIä»£ç†åœ°å€: {base_url}")
        logger.info(f"   ğŸ“š çŸ¥è¯†åº“è·¯å¾„: {self.knowledge_path}")
        logger.info(f"   ğŸ’¾ ç´¢å¼•å­˜å‚¨: {self.storage_path}")
        logger.info(f"   ğŸ” æŸ¥è¯¢å¼•æ“: å·²å°±ç»ª")
        
        return True

def main():
    """ä¸»å‡½æ•°"""
    import argparse
    
    parser = argparse.ArgumentParser(description="æ„å»ºRAGçŸ¥è¯†åº“ç³»ç»Ÿ (OpenAIä»£ç†ç‰ˆæœ¬)")
    parser.add_argument("--rebuild", action="store_true", help="å¼ºåˆ¶é‡å»ºç´¢å¼•")
    parser.add_argument("--knowledge", default="my_knowledge", help="çŸ¥è¯†åº“æ–‡ä»¶å¤¹è·¯å¾„")
    parser.add_argument("--storage", default="storage", help="ç´¢å¼•å­˜å‚¨è·¯å¾„")
    
    args = parser.parse_args()
    
    # åˆ›å»ºRAGæ„å»ºå™¨
    builder = RAGSystemBuilder(
        knowledge_path=args.knowledge,
        storage_path=args.storage
    )
    
    # æ„å»ºç³»ç»Ÿ
    success = builder.build_complete_system(force_rebuild=args.rebuild)
    
    if success:
        logger.info("âœ… RAGç³»ç»Ÿæ„å»ºæˆåŠŸï¼")
        logger.info("ğŸ’¡ ä¸‹ä¸€æ­¥ï¼šå¯åŠ¨åç«¯æœåŠ¡æµ‹è¯•æŸ¥è¯¢åŠŸèƒ½")
        sys.exit(0)
    else:
        logger.error("âŒ RAGç³»ç»Ÿæ„å»ºå¤±è´¥ï¼")
        logger.error("ğŸ’¡ è¯·æ£€æŸ¥æ—¥å¿—æ–‡ä»¶è·å–è¯¦ç»†é”™è¯¯ä¿¡æ¯")
        sys.exit(1)

if __name__ == "__main__":
    main() 