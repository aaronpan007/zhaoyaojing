#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
AIæƒ…æ„Ÿå®‰å…¨åŠ©æ‰‹ - RAGæŸ¥è¯¢ç³»ç»Ÿ (Replicateç‰ˆæœ¬)
æ™ºèƒ½æŸ¥è¯¢æœ¬åœ°çŸ¥è¯†åº“å¹¶è¿”å›ä¸“ä¸šåˆ†æç»“æœ
"""

import os
import sys
from pathlib import Path
import logging
from dotenv import load_dotenv
import json
import replicate
from typing import List

# LlamaIndexæ ¸å¿ƒæ¨¡å—
from llama_index.core import (
    StorageContext,
    load_index_from_storage,
    Settings
)
from llama_index.core.embeddings import BaseEmbedding

# è®¾ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

class ReplicateEmbedding(BaseEmbedding):
    """
    åŸºäºReplicate APIçš„è‡ªå®šä¹‰embeddingç±»
    ä½¿ç”¨é«˜è´¨é‡çš„BGE embeddingæ¨¡å‹
    ï¼ˆä¸build_rag_system.pyä¿æŒä¸€è‡´ï¼‰
    """
    
    def __init__(self, model_name: str = "nateraw/bge-large-en-v1.5", **kwargs):
        """
        åˆå§‹åŒ–Replicate Embedding
        
        Args:
            model_name: Replicateä¸Šçš„embeddingæ¨¡å‹åç§°
        """
        super().__init__(**kwargs)
        self.model_name = model_name
        
        # åˆå§‹åŒ–Replicateå®¢æˆ·ç«¯
        load_dotenv()
        self.api_token = os.getenv("REPLICATE_API_TOKEN")
        if not self.api_token:
            raise ValueError("æœªæ‰¾åˆ°REPLICATE_API_TOKENç¯å¢ƒå˜é‡ï¼è¯·åœ¨.envæ–‡ä»¶ä¸­é…ç½®æ‚¨çš„Replicate APIå¯†é’¥")
        
        # é…ç½®replicate
        os.environ["REPLICATE_API_TOKEN"] = self.api_token
        
        logger.debug(f"Replicate Embeddingåˆå§‹åŒ–å®Œæˆï¼Œä½¿ç”¨æ¨¡å‹: {self.model_name}")
    
    def _get_text_embedding(self, text: str) -> List[float]:
        """è·å–å•ä¸ªæ–‡æœ¬çš„embedding"""
        try:
            # è°ƒç”¨Replicate embedding API
            output = replicate.run(
                self.model_name,
                input={"text": text}
            )
            
            # å¤„ç†è¾“å‡ºæ ¼å¼
            if isinstance(output, list) and len(output) > 0:
                if isinstance(output[0], list):
                    # å¦‚æœæ˜¯åµŒå¥—åˆ—è¡¨ï¼Œå–ç¬¬ä¸€ä¸ª
                    embedding = output[0]
                else:
                    # å¦‚æœæ˜¯å•å±‚åˆ—è¡¨
                    embedding = output
            else:
                raise ValueError(f"æ„å¤–çš„embeddingè¾“å‡ºæ ¼å¼: {type(output)}")
            
            # ç¡®ä¿è¿”å›çš„æ˜¯floatåˆ—è¡¨
            return [float(x) for x in embedding]
            
        except Exception as e:
            logger.error(f"Replicate embeddingè°ƒç”¨å¤±è´¥: {str(e)}")
            raise e
    
    def _get_query_embedding(self, query: str) -> List[float]:
        """è·å–æŸ¥è¯¢æ–‡æœ¬çš„embeddingï¼ˆä¸æ–‡æ¡£embeddingç›¸åŒï¼‰"""
        return self._get_text_embedding(query)
    
    def _get_text_embeddings(self, texts: List[str]) -> List[List[float]]:
        """æ‰¹é‡è·å–æ–‡æœ¬embedding"""
        embeddings = []
        for text in texts:
            embedding = self._get_text_embedding(text)
            embeddings.append(embedding)
        return embeddings
    
    async def _aget_query_embedding(self, query: str) -> List[float]:
        """å¼‚æ­¥è·å–æŸ¥è¯¢embedding"""
        return self._get_query_embedding(query)
    
    async def _aget_text_embedding(self, text: str) -> List[float]:
        """å¼‚æ­¥è·å–æ–‡æœ¬embedding"""
        return self._get_text_embedding(text)

class RAGQueryService:
    """RAGæŸ¥è¯¢æœåŠ¡ç±» - Replicateç‰ˆæœ¬"""
    
    def __init__(self, storage_path: str = "storage"):
        """
        åˆå§‹åŒ–RAGæŸ¥è¯¢æœåŠ¡
        
        Args:
            storage_path: ç´¢å¼•å­˜å‚¨è·¯å¾„
        """
        self.storage_path = Path(storage_path)
        self.index = None
        self.query_engine = None
        
        # é…ç½®LlamaIndexè®¾ç½®
        self._setup_llama_index()
        
        # åŠ è½½ç´¢å¼•
        self.load_index()
    
    def _setup_llama_index(self):
        """é…ç½®LlamaIndexå…¨å±€è®¾ç½® - ä½¿ç”¨Replicate"""
        load_dotenv()
        
        # æ£€æŸ¥Replicate APIå¯†é’¥
        api_token = os.getenv("REPLICATE_API_TOKEN")
        if not api_token:
            logger.error("æœªæ‰¾åˆ°REPLICATE_API_TOKENç¯å¢ƒå˜é‡ï¼è¯·åœ¨.envæ–‡ä»¶ä¸­é…ç½®æ‚¨çš„Replicate APIå¯†é’¥")
            sys.exit(1)
        
        # é…ç½®è‡ªå®šä¹‰Replicate Embeddingæ¨¡å‹
        Settings.embed_model = ReplicateEmbedding(
            model_name="nateraw/bge-large-en-v1.5",  # ä½¿ç”¨é«˜è´¨é‡çš„BGEæ¨¡å‹
            embed_batch_size=1  # Replicate APIé€šå¸¸æ¯æ¬¡å¤„ç†ä¸€ä¸ªæ–‡æœ¬
        )
        
        # ä¸è®¾ç½®LLMï¼Œå› ä¸ºæˆ‘ä»¬åœ¨åç«¯å•ç‹¬å¤„ç†
        Settings.llm = None
        
        logger.debug("LlamaIndexé…ç½®å®Œæˆ (Replicate BGE Embedding)")
    
    def load_index(self):
        """åŠ è½½å·²å­˜åœ¨çš„ç´¢å¼•"""
        if not (self.storage_path / "index_store.json").exists():
            logger.error(f"æœªæ‰¾åˆ°ç´¢å¼•æ–‡ä»¶: {self.storage_path}/index_store.json")
            logger.error("è¯·å…ˆè¿è¡Œ python build_rag_system.py æ¥æ„å»ºç´¢å¼•")
            return False
        
        logger.info("ğŸ”„ åŠ è½½RAGç´¢å¼•...")
        
        try:
            # ä»å­˜å‚¨ä¸­åŠ è½½ç´¢å¼•
            storage_context = StorageContext.from_defaults(persist_dir=str(self.storage_path))
            self.index = load_index_from_storage(storage_context)
            
            # åˆ›å»ºæŸ¥è¯¢å¼•æ“
            self.query_engine = self.index.as_query_engine(
                similarity_top_k=5,  # è¿”å›æœ€ç›¸ä¼¼çš„5ä¸ªæ–‡æ¡£ç‰‡æ®µ
                response_mode="compact"  # ç´§å‡‘æ¨¡å¼å›ç­”
            )
            
            logger.info("âœ… RAGç³»ç»ŸåŠ è½½å®Œæˆ")
            return True
            
        except Exception as e:
            logger.error(f"âŒ åŠ è½½ç´¢å¼•å¤±è´¥: {str(e)}")
            return False
    
    def query(self, question: str, context: str = "", diagnostic_mode: bool = False) -> dict:
        """
        æ‰§è¡Œæ™ºèƒ½æŸ¥è¯¢
        
        Args:
            question: æŸ¥è¯¢é—®é¢˜
            context: é¢å¤–ä¸Šä¸‹æ–‡ä¿¡æ¯
            diagnostic_mode: æ˜¯å¦å¯ç”¨è¯Šæ–­æ¨¡å¼ï¼Œè¯¦ç»†æ‰“å°æ£€ç´¢ä¿¡æ¯
            
        Returns:
            åŒ…å«æŸ¥è¯¢ç»“æœçš„å­—å…¸
        """
        if not self.query_engine:
            return {
                "error": "RAGç³»ç»Ÿæœªå°±ç»ª",
                "answer": "",
                "sources": []
            }
        
        # æ„å»ºå®Œæ•´æŸ¥è¯¢
        full_query = question
        if context.strip():
            full_query = f"ä¸Šä¸‹æ–‡ä¿¡æ¯: {context.strip()}\n\né—®é¢˜: {question}"
        
        logger.info(f"ğŸ” æ‰§è¡ŒæŸ¥è¯¢: {question}")
        
        try:
            # æ‰§è¡ŒæŸ¥è¯¢
            response = self.query_engine.query(full_query)
            
            # æå–æºæ–‡æ¡£ä¿¡æ¯
            sources = []
            if hasattr(response, 'source_nodes') and response.source_nodes:
                # ğŸ” è¯Šæ–­æ¨¡å¼ï¼šè¯¦ç»†æ‰“å°æ£€ç´¢ä¿¡æ¯
                if diagnostic_mode:
                    print("\n" + "="*80)
                    print("ğŸ”¬ RAGç³»ç»Ÿæ£€ç´¢è¯Šæ–­æŠ¥å‘Š")
                    print("="*80)
                    print(f"ğŸ“ æŸ¥è¯¢é—®é¢˜: {question}")
                    if context.strip():
                        print(f"ğŸ“„ ä¸Šä¸‹æ–‡: {context}")
                    print(f"ğŸ” å®Œæ•´æŸ¥è¯¢: {full_query}")
                    print(f"ğŸ“Š æ£€ç´¢åˆ° {len(response.source_nodes)} ä¸ªç›¸å…³æ–‡æ¡£ç‰‡æ®µ\n")
                
                for i, node in enumerate(response.source_nodes, 1):
                    source_info = {
                        "content": node.text[:200] + "..." if len(node.text) > 200 else node.text,
                        "score": getattr(node, 'score', 0.0)
                    }
                    
                    # æ·»åŠ æ–‡ä»¶è·¯å¾„ä¿¡æ¯ï¼ˆå¦‚æœæœ‰ï¼‰
                    if hasattr(node, 'metadata') and 'file_path' in node.metadata:
                        source_info['file_path'] = node.metadata['file_path']
                    
                    # ğŸ” è¯Šæ–­æ¨¡å¼ï¼šè¯¦ç»†æ‰“å°æ¯ä¸ªæ£€ç´¢ç‰‡æ®µ
                    if diagnostic_mode:
                        print(f"ğŸ“„ ç‰‡æ®µ {i}")
                        print("-" * 60)
                        
                        # ç›¸å…³æ€§å¾—åˆ†
                        score = getattr(node, 'score', 0.0)
                        print(f"ğŸ¯ ç›¸å…³æ€§å¾—åˆ†: {score:.4f}")
                        
                        # æ¥æºå…ƒæ•°æ®
                        metadata = getattr(node, 'metadata', {})
                        if 'file_path' in metadata:
                            file_name = os.path.basename(metadata['file_path'])
                            print(f"ğŸ“ æ¥æºæ–‡ä»¶: {file_name}")
                            print(f"ğŸ“‚ å®Œæ•´è·¯å¾„: {metadata['file_path']}")
                        
                        # å…¶ä»–å…ƒæ•°æ®ä¿¡æ¯
                        if metadata:
                            for key, value in metadata.items():
                                if key != 'file_path':
                                    print(f"ğŸ“‹ {key}: {value}")
                        
                        # åŸå§‹æ–‡æœ¬å—
                        print(f"ğŸ“ åŸå§‹æ–‡æœ¬å— (é•¿åº¦: {len(node.text)} å­—ç¬¦):")
                        print("-" * 40)
                        print(node.text)
                        print("-" * 40)
                        
                        # æ–‡æœ¬å—IDï¼ˆå¦‚æœæœ‰ï¼‰
                        if hasattr(node, 'node_id'):
                            print(f"ğŸ†” èŠ‚ç‚¹ID: {node.node_id}")
                        
                        print()  # ç©ºè¡Œåˆ†éš”
                    
                    sources.append(source_info)
                
                # ğŸ” è¯Šæ–­æ¨¡å¼ï¼šæ‰“å°æ–‡æ¡£æ¥æºç»Ÿè®¡
                if diagnostic_mode:
                    print("ğŸ“Š æ–‡æ¡£æ¥æºç»Ÿè®¡:")
                    print("-" * 40)
                    file_count = {}
                    for source in sources:
                        if 'file_path' in source:
                            file_name = os.path.basename(source['file_path'])
                            file_count[file_name] = file_count.get(file_name, 0) + 1
                    
                    for file_name, count in sorted(file_count.items(), key=lambda x: x[1], reverse=True):
                        print(f"ğŸ“‚ {file_name}: {count} ä¸ªç‰‡æ®µ")
                    
                    print("\nğŸ’¡ æ£€ç´¢åè§åˆ†æ:")
                    print("-" * 40)
                    total_sources = len(sources)
                    if total_sources > 0:
                        most_cited = max(file_count.items(), key=lambda x: x[1])
                        bias_ratio = most_cited[1] / total_sources
                        print(f"ğŸ” æœ€å¸¸å¼•ç”¨æ–‡æ¡£: {most_cited[0]} ({most_cited[1]}/{total_sources} = {bias_ratio:.1%})")
                        if bias_ratio > 0.6:
                            print("âš ï¸  è­¦å‘Š: å­˜åœ¨æ˜æ˜¾çš„æ£€ç´¢åè§ï¼å•ä¸€æ–‡æ¡£å æ¯”è¿‡é«˜")
                        elif bias_ratio > 0.4:
                            print("ğŸŸ¡ æ³¨æ„: å­˜åœ¨è½»å¾®çš„æ£€ç´¢åè§")
                        else:
                            print("âœ… æ£€ç´¢ç»“æœç›¸å¯¹å‡è¡¡")
                    
                    print("="*80)
                    print("ğŸ”¬ è¯Šæ–­æŠ¥å‘Šç»“æŸ")
                    print("="*80 + "\n")
            
            result = {
                "answer": str(response),
                "sources": sources,
                "query": question,
                "context": context
            }
            
            logger.info("âœ… æŸ¥è¯¢å®Œæˆ")
            return result
            
        except Exception as e:
            logger.error(f"âŒ æŸ¥è¯¢å¤±è´¥: {str(e)}")
            return {
                "error": str(e),
                "answer": "",
                "sources": [],
                "query": question,
                "context": context
            }

def create_rag_query(user_input: dict, image_analysis: list) -> str:
    """
    æ ¹æ®ç”¨æˆ·è¾“å…¥å’Œå›¾ç‰‡åˆ†æï¼Œæ„é€ ä¸“ä¸šçš„RAGæŸ¥è¯¢é—®é¢˜
    
    Args:
        user_input: ç”¨æˆ·è¾“å…¥ä¿¡æ¯
        image_analysis: å›¾ç‰‡åˆ†æç»“æœ
        
    Returns:
        æ„é€ çš„æŸ¥è¯¢é—®é¢˜
    """
    # åŸºç¡€æŸ¥è¯¢
    base_query = f"""
è¯·åˆ†æä»¥ä¸‹çº¦ä¼šå¯¹è±¡çš„æƒ…å†µå¹¶æä¾›ä¸“ä¸šå»ºè®®ï¼š

ä¸ªäººä¿¡æ¯ï¼š
- æ˜µç§°ï¼š{user_input.get('nickname', 'æœªçŸ¥')}
- èŒä¸šï¼š{user_input.get('profession', 'æœªçŸ¥')}
- å¹´é¾„ï¼š{user_input.get('age', 'æœªçŸ¥')}
- ä¸ªäººç®€ä»‹ï¼š{user_input.get('bio', 'æœªæä¾›')}
"""
    
    # æ·»åŠ å›¾ç‰‡åˆ†æä¿¡æ¯
    if image_analysis:
        base_query += "\nå›¾ç‰‡åˆ†æç»“æœï¼š\n"
        for i, analysis in enumerate(image_analysis, 1):
            base_query += f"{i}. {analysis}\n"
    
    # æ·»åŠ å…·ä½“æŸ¥è¯¢é—®é¢˜
    base_query += """
åŸºäºä¸Šè¿°ä¿¡æ¯ï¼Œè¯·ä»ä»¥ä¸‹è§’åº¦è¿›è¡Œä¸“ä¸šåˆ†æï¼š
1. çº¢æ——ä¿¡å·è¯†åˆ«ï¼šæ˜¯å¦å­˜åœ¨PUAè¡Œä¸ºæ¨¡å¼ã€æƒ…æ„Ÿæ“æ§è¿¹è±¡ï¼Ÿ
2. å®‰å…¨é£é™©è¯„ä¼°ï¼šçº¦ä¼šè¿‡ç¨‹ä¸­éœ€è¦æ³¨æ„çš„å®‰å…¨äº‹é¡¹
3. è¡Œä¸ºæ¨¡å¼åˆ†æï¼šå¯¹æ–¹çš„æ²Ÿé€šé£æ ¼å’Œè¡Œä¸ºç‰¹å¾åæ˜ äº†ä»€ä¹ˆï¼Ÿ
4. å»ºè®®ä¸é¢„é˜²ï¼šå¦‚ä½•ä¿æŠ¤è‡ªå·±ï¼Œå»ºç«‹å¥åº·çš„æƒ…æ„Ÿè¾¹ç•Œï¼Ÿ

è¯·æä¾›å…·ä½“ã€å®ç”¨çš„å»ºè®®ï¼Œå¹¶å¼•ç”¨ç›¸å…³çš„å¿ƒç†å­¦å’Œä¸¤æ€§å…³ç³»ç†è®ºã€‚
"""
    
    return base_query

def generate_final_report(rag_result: dict, user_input: dict, image_analysis: list) -> dict:
    """
    ç”Ÿæˆæœ€ç»ˆçš„ç»“æ„åŒ–åˆ†ææŠ¥å‘Š
    
    Args:
        rag_result: RAGæŸ¥è¯¢ç»“æœ
        user_input: ç”¨æˆ·è¾“å…¥ä¿¡æ¯
        image_analysis: å›¾ç‰‡åˆ†æç»“æœ
        
    Returns:
        ç»“æ„åŒ–çš„åˆ†ææŠ¥å‘Š
    """
    report = {
        "title": "AIæƒ…æ„Ÿå®‰å…¨åˆ†ææŠ¥å‘Š (Replicate RAGç‰ˆæœ¬)",
        "timestamp": "",
        "user_data": {
            "target_nickname": user_input.get('nickname', 'æœªçŸ¥'),
            "target_profession": user_input.get('profession', 'æœªçŸ¥'),
            "target_age": user_input.get('age', 'æœªçŸ¥'),
            "target_bio": user_input.get('bio', 'æœªæä¾›')
        },
        "image_analysis": image_analysis,
        "rag_analysis": {
            "query": rag_result.get('query', ''),
            "answer": rag_result.get('answer', ''),
            "sources_count": len(rag_result.get('sources', [])),
            "knowledge_references": rag_result.get('sources', [])
        },
        "risk_assessment": {
            "overall_risk": "éœ€è¦ä¸“ä¸šè¯„ä¼°",
            "red_flags": [],
            "safety_tips": []
        },
        "recommendations": [],
        "api_status": {
            "rag_system": "active" if not rag_result.get('error') else "error",
            "embedding_model": "Replicate BGE-large-en-v1.5",
            "knowledge_base": "æœ¬åœ°ä¸“ä¸šèµ„æ–™åº“"
        }
    }
    
    # å¦‚æœæœ‰é”™è¯¯ï¼Œè®°å½•é”™è¯¯ä¿¡æ¯
    if rag_result.get('error'):
        report["error"] = rag_result['error']
    
    return report

def main():
    """ä¸»å‡½æ•° - æ”¯æŒäº¤äº’å¼å’Œå‘½ä»¤è¡ŒæŸ¥è¯¢"""
    import argparse
    
    parser = argparse.ArgumentParser(description="RAGæ™ºèƒ½æŸ¥è¯¢ç³»ç»Ÿ (Replicateç‰ˆæœ¬)")
    parser.add_argument("query", nargs="?", help="æŸ¥è¯¢é—®é¢˜")
    parser.add_argument("--context", default="", help="é¢å¤–ä¸Šä¸‹æ–‡ä¿¡æ¯")
    parser.add_argument("--storage", default="storage", help="ç´¢å¼•å­˜å‚¨è·¯å¾„")
    parser.add_argument("--json", action="store_true", help="è¾“å‡ºJSONæ ¼å¼ç»“æœ")
    parser.add_argument("--diagnostic", action="store_true", help="å¯ç”¨è¯Šæ–­æ¨¡å¼ï¼Œè¯¦ç»†æ˜¾ç¤ºæ£€ç´¢è¿‡ç¨‹")
    
    args = parser.parse_args()
    
    # åˆå§‹åŒ–RAGæœåŠ¡
    rag_service = RAGQueryService(storage_path=args.storage)
    
    if not rag_service.query_engine:
        logger.error("âŒ RAGç³»ç»Ÿåˆå§‹åŒ–å¤±è´¥")
        sys.exit(1)
    
    if args.query:
        # å‘½ä»¤è¡Œæ¨¡å¼
        result = rag_service.query(args.query, args.context, diagnostic_mode=args.diagnostic)
        
        if args.json:
            print(json.dumps(result, ensure_ascii=False, indent=2))
        else:
            if result.get('error'):
                logger.error(f"æŸ¥è¯¢é”™è¯¯: {result['error']}")
            else:
                print(f"\né—®é¢˜: {result['query']}")
                print(f"å›ç­”: {result['answer']}")
                if result['sources']:
                    print(f"\nå‚è€ƒæ¥æº: {len(result['sources'])} ä¸ªæ–‡æ¡£ç‰‡æ®µ")
    else:
        # äº¤äº’å¼æ¨¡å¼
        print("ğŸ¤– AIæƒ…æ„Ÿå®‰å…¨åŠ©æ‰‹ - RAGæŸ¥è¯¢ç³»ç»Ÿ (Replicateç‰ˆæœ¬)")
        if args.diagnostic:
            print("ğŸ”¬ è¯Šæ–­æ¨¡å¼å·²å¯ç”¨")
        print("ğŸ’¡ è¾“å…¥æ‚¨çš„é—®é¢˜ï¼Œè¾“å…¥ 'quit' é€€å‡º")
        print("ğŸ“ è¾“å…¥ '/diagnostic' åˆ‡æ¢è¯Šæ–­æ¨¡å¼")
        print("=" * 50)
        
        diagnostic_mode = args.diagnostic  # ä»å‘½ä»¤è¡Œå‚æ•°åˆå§‹åŒ–
        
        while True:
            try:
                question = input(f"\nğŸ” è¯·è¾“å…¥æ‚¨çš„é—®é¢˜{' (è¯Šæ–­æ¨¡å¼)' if diagnostic_mode else ''}: ").strip()
                
                if question.lower() in ['quit', 'exit', 'q']:
                    print("ğŸ‘‹ å†è§ï¼")
                    break
                
                if question.lower() == '/diagnostic':
                    diagnostic_mode = not diagnostic_mode
                    status = "å¯ç”¨" if diagnostic_mode else "å…³é—­"
                    print(f"ğŸ”¬ è¯Šæ–­æ¨¡å¼å·²{status}")
                    continue
                
                if not question:
                    continue
                
                result = rag_service.query(question, diagnostic_mode=diagnostic_mode)
                
                if result.get('error'):
                    print(f"âŒ æŸ¥è¯¢é”™è¯¯: {result['error']}")
                else:
                    print(f"\nğŸ“‹ å›ç­”:")
                    print(result['answer'])
                    
                    if result['sources'] and not diagnostic_mode:
                        print(f"\nğŸ“š å‚è€ƒæ¥æº: {len(result['sources'])} ä¸ªæ–‡æ¡£ç‰‡æ®µ")
                        for i, source in enumerate(result['sources'][:3], 1):
                            print(f"   {i}. {source['content'][:100]}...")
            
            except KeyboardInterrupt:
                print("\nğŸ‘‹ å†è§ï¼")
                break
            except Exception as e:
                print(f"âŒ å‘ç”Ÿé”™è¯¯: {str(e)}")

if __name__ == "__main__":
    main() 