#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ç®€åŒ–ç‰ˆ RAGæŸ¥è¯¢æœåŠ¡æ¨¡å— (Cloudflare R2ç‰ˆæœ¬)
ä¸‹è½½R2ç´¢å¼•æ–‡ä»¶åˆ°ä¸´æ—¶ç›®å½•ï¼Œç„¶åä½¿ç”¨æ ‡å‡†æ–¹æ³•åŠ è½½
"""

# ä¼˜å…ˆåŠ è½½ç¯å¢ƒå˜é‡ - å¿…é¡»åœ¨æ‰€æœ‰å…¶ä»–ä»£ç ä¹‹å‰
from dotenv import load_dotenv
load_dotenv()

import os
import sys
import json
import logging
import tempfile
import shutil
from pathlib import Path
from typing import List, Dict, Any

# å®Œå…¨ç¦ç”¨æ‰€æœ‰å¯èƒ½çš„è¾“å‡ºåˆ°stdout
import warnings
warnings.filterwarnings('ignore')

# é‡å®šå‘æ‰€æœ‰å¯èƒ½çš„è¾“å‡ºåˆ°null
class DevNull:
    def write(self, msg):
        pass
    def flush(self):
        pass

# åœ¨å¯¼å…¥LlamaIndexä¹‹å‰ï¼Œå…ˆè®¾ç½®ç¯å¢ƒå˜é‡ç¦ç”¨verboseè¾“å‡º
os.environ["LLAMA_INDEX_LOGGING_LEVEL"] = "CRITICAL"
os.environ["TOKENIZERS_PARALLELISM"] = "false"

# ä¸´æ—¶é‡å®šå‘stdoutï¼Œé˜²æ­¢LlamaIndexçš„å¯¼å…¥æ—¶è¾“å‡º
original_stdout = sys.stdout
sys.stdout = DevNull()

try:
    # LlamaIndexæ ¸å¿ƒæ¨¡å—
    from llama_index.core import (
        StorageContext,
        load_index_from_storage,
        Settings
    )
    from llama_index.embeddings.openai import OpenAIEmbedding
    from llama_index.core.llms import MockLLM
    
    # S3FSæ–‡ä»¶ç³»ç»Ÿï¼ˆS3å…¼å®¹ï¼‰
    import s3fs
    
finally:
    # æ¢å¤stdout
    sys.stdout = original_stdout

# é…ç½®æ—¥å¿—ï¼Œé‡å®šå‘åˆ°stderré¿å…æ±¡æŸ“stdout
logging.basicConfig(
    level=logging.CRITICAL,  # åªè¾“å‡ºä¸¥é‡é”™è¯¯
    stream=sys.stderr,       # é‡å®šå‘åˆ°stderr
    format='%(message)s'
)
logger = logging.getLogger(__name__)

class RAGR2SimpleQueryService:
    """ç®€åŒ–ç‰ˆ RAGæŸ¥è¯¢æœåŠ¡ç±» - Cloudflare R2ç‰ˆæœ¬"""
    
    def __init__(self):
        """
        åˆå§‹åŒ–RAGæŸ¥è¯¢æœåŠ¡ - ä½¿ç”¨Cloudflare R2äº‘å­˜å‚¨
        """
        self.index = None
        self.query_engine = None
        self.s3fs = None
        self.temp_dir = None
        
        # åˆå§‹åŒ–çŠ¶æ€
        self.is_initialized = False
        self.initialization_error = None
        
        try:
            # éªŒè¯R2é…ç½®
            self._validate_r2_config()
            
            # é…ç½®LlamaIndexè®¾ç½®
            self._setup_llama_index()
            
            # åˆå§‹åŒ–S3FSæ–‡ä»¶ç³»ç»Ÿ
            self._setup_s3fs()
            
            # ä¸‹è½½å¹¶åŠ è½½ç´¢å¼•
            if self.download_and_load_index():
                self.is_initialized = True
            else:
                self.initialization_error = "ä»R2ä¸‹è½½å¹¶åŠ è½½ç´¢å¼•å¤±è´¥"
                
        except Exception as e:
            self.initialization_error = str(e)
            logger.error(f"RAGç³»ç»Ÿåˆå§‹åŒ–å¤±è´¥: {str(e)}")
    
    def _validate_r2_config(self):
        """éªŒè¯Cloudflare R2é…ç½®"""
        required_vars = [
            "CLOUDFLARE_ACCOUNT_ID",
            "R2_ACCESS_KEY_ID", 
            "R2_SECRET_ACCESS_KEY",
            "BUCKET_NAME"
        ]
        
        missing_vars = []
        for var in required_vars:
            if not os.getenv(var):
                missing_vars.append(var)
        
        if missing_vars:
            raise ValueError(f"ç¼ºå°‘å¿…éœ€çš„ç¯å¢ƒå˜é‡: {', '.join(missing_vars)}")
    
    def _setup_llama_index(self):
        """é…ç½®LlamaIndexå…¨å±€è®¾ç½® - ä½¿ç”¨OpenAI"""
        
        # æ£€æŸ¥OpenAI APIå¯†é’¥
        openai_api_key = os.getenv("OPENAI_API_KEY")
        if not openai_api_key:
            raise ValueError("æœªæ‰¾åˆ°OPENAI_API_KEYç¯å¢ƒå˜é‡ï¼è¯·åœ¨.envæ–‡ä»¶ä¸­é…ç½®æ‚¨çš„OpenAI APIå¯†é’¥")
        
        # è·å–OpenAI APIåŸºç¡€URL
        openai_api_base = os.getenv("OPENAI_API_BASE", "https://api.openai.com/v1")
        
        # ä½¿ç”¨OpenAI embedding
        Settings.embed_model = OpenAIEmbedding(
            model="text-embedding-3-small",
            api_key=openai_api_key,
            api_base=openai_api_base
        )
        
        # ä½¿ç”¨MockLLMé¿å…LLMè°ƒç”¨ï¼ŒåŒæ—¶è®¾ç½®æå…¶ä¿å®ˆçš„å‚æ•°
        Settings.llm = MockLLM(max_tokens=128)
        
        # è®¾ç½®æå…¶ä¿å®ˆçš„ä¸Šä¸‹æ–‡å‚æ•°é¿å…è¶…å‡ºé™åˆ¶
        Settings.chunk_size = 128    # æå°çš„chunk size
        Settings.chunk_overlap = 20   # æå°çš„overlap
        Settings.context_window = 512 # æå°çš„ä¸Šä¸‹æ–‡çª—å£
        Settings.num_output = 64      # æå°çš„è¾“å‡ºé•¿åº¦
    
    def _setup_s3fs(self):
        """åˆå§‹åŒ–S3FSæ–‡ä»¶ç³»ç»Ÿè¿æ¥R2"""
        account_id = os.getenv("CLOUDFLARE_ACCOUNT_ID")
        access_key = os.getenv("R2_ACCESS_KEY_ID")
        secret_key = os.getenv("R2_SECRET_ACCESS_KEY")
        
        # Cloudflare R2çš„endpoint URLæ ¼å¼
        endpoint_url = f"https://{account_id}.r2.cloudflarestorage.com"
        
        try:
            self.s3fs = s3fs.S3FileSystem(
                key=access_key,
                secret=secret_key,
                endpoint_url=endpoint_url,
                use_ssl=True
            )
            
            # æµ‹è¯•è¿æ¥
            bucket_name = os.getenv("BUCKET_NAME")
            if not self.s3fs.exists(bucket_name):
                raise ValueError(f"R2å­˜å‚¨æ¡¶ä¸å­˜åœ¨æˆ–æ— æ³•è®¿é—®: {bucket_name}")
        except Exception as e:
            raise ValueError(f"è¿æ¥Cloudflare R2å¤±è´¥: {str(e)}")
    
    def download_and_load_index(self):
        """ä»R2ä¸‹è½½ç´¢å¼•æ–‡ä»¶åˆ°ä¸´æ—¶ç›®å½•å¹¶åŠ è½½"""
        try:
            bucket_name = os.getenv("BUCKET_NAME")
            
            # åˆ›å»ºä¸´æ—¶ç›®å½•
            self.temp_dir = tempfile.mkdtemp(prefix="rag_r2_")
            temp_storage = Path(self.temp_dir)
            
            # éœ€è¦ä¸‹è½½çš„æ–‡ä»¶
            required_files = [
                "index_store.json",
                "default__vector_store.json",
                "docstore.json"
            ]
            
            # ä¸‹è½½å¿…éœ€æ–‡ä»¶
            for filename in required_files:
                remote_path = f"{bucket_name}/{filename}"
                local_path = temp_storage / filename
                
                if not self.s3fs.exists(remote_path):
                    logger.error(f"R2ä¸­æœªæ‰¾åˆ°å¿…éœ€æ–‡ä»¶: {remote_path}")
                    return False
                
                # ä¸‹è½½æ–‡ä»¶
                self.s3fs.get_file(remote_path, str(local_path))
                
                if not local_path.exists():
                    logger.error(f"ä¸‹è½½æ–‡ä»¶å¤±è´¥: {filename}")
                    return False
            
            # ä¸´æ—¶é‡å®šå‘stdoutï¼Œé˜²æ­¢loadingä¿¡æ¯è¾“å‡º
            original_stdout = sys.stdout
            sys.stdout = DevNull()
            
            try:
                # ä»ä¸´æ—¶ç›®å½•åŠ è½½ç´¢å¼•
                storage_context = StorageContext.from_defaults(persist_dir=str(temp_storage))
                self.index = load_index_from_storage(storage_context)
                
                # åˆ›å»ºæŸ¥è¯¢å¼•æ“
                self.query_engine = self.index.as_query_engine(
                    similarity_top_k=5,         # ä¼˜åŒ–ï¼šå–5ä¸ªæœ€ç›¸å…³çš„æ–‡æ¡£ç‰‡æ®µï¼Œæå‡çŸ¥è¯†åº“è¦†ç›–åº¦
                    response_mode="compact",    # ä½¿ç”¨compactæ¨¡å¼
                    text_qa_template=None,      # ä¸ä½¿ç”¨æ¨¡æ¿
                    streaming=False,
                    verbose=False               # ç¦ç”¨verboseè¾“å‡º
                )
                
            finally:
                # æ¢å¤stdout
                sys.stdout = original_stdout
            
            return True
            
        except Exception as e:
            logger.error(f"ä»R2ä¸‹è½½å¹¶åŠ è½½ç´¢å¼•å¤±è´¥: {str(e)}")
            return False
    
    def cleanup(self):
        """æ¸…ç†ä¸´æ—¶æ–‡ä»¶"""
        if self.temp_dir and Path(self.temp_dir).exists():
            try:
                shutil.rmtree(self.temp_dir)
            except:
                pass
    
    def __del__(self):
        """ææ„å‡½æ•°ï¼Œè‡ªåŠ¨æ¸…ç†"""
        self.cleanup()
    
    def query(self, question: str, context: str = "", diagnostic_mode: bool = False) -> Dict[str, Any]:
        """
        æ‰§è¡ŒRAGæŸ¥è¯¢
        
        Args:
            question: æŸ¥è¯¢é—®é¢˜
            context: é¢å¤–ä¸Šä¸‹æ–‡
            diagnostic_mode: æ˜¯å¦å¯ç”¨è¯Šæ–­æ¨¡å¼ï¼Œè¾“å‡ºè¯¦ç»†æ£€ç´¢ä¿¡æ¯åˆ°stderr
            
        Returns:
            æŸ¥è¯¢ç»“æœå­—å…¸
        """
        if not self.is_initialized:
            return {
                "error": f"RAGç³»ç»Ÿæœªåˆå§‹åŒ–: {self.initialization_error}",
                "answer": "",
                "sources": [],
                "query": question,
                "context": context,
                "sources_count": 0
            }
        
        try:
            # æ„å»ºæŸ¥è¯¢ - æˆªæ–­è¿‡é•¿çš„å†…å®¹é¿å…ä¸Šä¸‹æ–‡è¶…é™
            if len(question) > 100:
                question = question[:100] + "..."
            
            if context and len(context) > 50:
                context = context[:50] + "..."
            
            full_query = f"{question}\n{context}" if context else question
            
            # ä¸´æ—¶é‡å®šå‘stdoutï¼Œé˜²æ­¢æŸ¥è¯¢è¿‡ç¨‹çš„è¾“å‡º
            original_stdout = sys.stdout
            sys.stdout = DevNull()
            
            try:
                # æ‰§è¡ŒæŸ¥è¯¢
                response = self.query_engine.query(full_query)
            finally:
                # æ¢å¤stdout
                sys.stdout = original_stdout
            
            # æå–æºä¿¡æ¯
            sources = []
            if hasattr(response, 'source_nodes'):
                # ğŸ” è¯Šæ–­æ¨¡å¼ï¼šè¯¦ç»†è¾“å‡ºæ£€ç´¢ä¿¡æ¯åˆ°stderr
                if diagnostic_mode:
                    logger.info(f"ğŸ” R2æ£€ç´¢åˆ° {len(response.source_nodes)} ä¸ªç›¸å…³æ–‡æ¡£ç‰‡æ®µ:")
                
                for i, node in enumerate(response.source_nodes):
                    similarity_score = getattr(node, 'score', 0.0)
                    
                    # è·å–å…ƒæ•°æ®
                    metadata = getattr(node.node, 'metadata', {})
                    file_name = metadata.get('file_name', 'unknown')
                    file_path = metadata.get('file_path', '')
                    
                    # æˆªæ–­æ–‡æœ¬å†…å®¹è¿›è¡Œé¢„è§ˆ
                    text_preview = node.node.text[:200] + "..." if len(node.node.text) > 200 else node.node.text
                    
                    source_info = {
                        "file_name": file_name,
                        "file_path": file_path,
                        "similarity_score": round(similarity_score, 3),
                        "text_preview": text_preview,
                        "node_id": node.node.node_id
                    }
                    
                    sources.append(source_info)
                    
                    # ğŸ” è¯Šæ–­æ¨¡å¼ï¼šè¾“å‡ºè¯¦ç»†ä¿¡æ¯åˆ°stderr
                    if diagnostic_mode:
                        logger.info(f"  ğŸ“„ R2ç‰‡æ®µ {i+1}: {file_name}")
                        logger.info(f"     ç›¸ä¼¼åº¦: {similarity_score:.3f}")
                        logger.info(f"     é¢„è§ˆ: {text_preview[:100]}...")
                        logger.info("")
            
            # ğŸ” è¯Šæ–­æ¨¡å¼ï¼šè¾“å‡ºæœ€ç»ˆç­”æ¡ˆåˆ°stderr
            if diagnostic_mode:
                logger.info(f"ğŸ¯ R2 RAGç³»ç»Ÿè¿”å›ç­”æ¡ˆ:")
                logger.info(f"   æŸ¥è¯¢: {question}")
                logger.info(f"   ç­”æ¡ˆ: {str(response)[:200]}...")
                logger.info(f"   ä½¿ç”¨R2æºæ•°é‡: {len(sources)}")
                logger.info("=" * 50)
            
            return {
                "answer": str(response),
                "sources": sources,
                "query": question,
                "context": context,
                "sources_count": len(sources),
                "storage_type": "cloudflare_r2_simple"
            }
            
        except Exception as e:
            logger.error(f"RAGæŸ¥è¯¢å¤±è´¥: {str(e)}")
            return {
                "error": f"æŸ¥è¯¢å¤±è´¥: {str(e)}",
                "answer": "",
                "sources": [],
                "query": question,
                "context": context,
                "sources_count": 0
            }

def stdin_handler():
    """å¤„ç†ä»stdinè¾“å…¥çš„JSONæŸ¥è¯¢"""
    try:
        # è¯»å–stdinä¸­çš„JSONæ•°æ®
        input_data = sys.stdin.read().strip()
        
        if not input_data:
            return {
                "error": "æœªæ”¶åˆ°è¾“å…¥æ•°æ®",
                "answer": "",
                "sources": [],
                "sources_count": 0
            }
        
        # è§£æJSON
        try:
            data = json.loads(input_data)
        except json.JSONDecodeError as e:
            return {
                "error": f"JSONè§£æå¤±è´¥: {str(e)}",
                "answer": "",
                "sources": [],
                "sources_count": 0
            }
        
        # æå–æŸ¥è¯¢å‚æ•°
        query = data.get('query', '')
        context = data.get('context', '')
        diagnostic_mode = data.get('diagnostic_mode', False)
        
        if not query:
            return {
                "error": "ç¼ºå°‘queryå‚æ•°",
                "answer": "",
                "sources": [],
                "sources_count": 0
            }
        
        # åˆ›å»ºæœåŠ¡å®ä¾‹å¹¶æ‰§è¡ŒæŸ¥è¯¢
        service = RAGR2SimpleQueryService()
        
        if not service.is_initialized:
            return {
                "error": f"RAGç³»ç»Ÿåˆå§‹åŒ–å¤±è´¥: {service.initialization_error}",
                "answer": "",
                "sources": [],
                "sources_count": 0
            }
        
        # æ‰§è¡ŒæŸ¥è¯¢
        result = service.query(query, context, diagnostic_mode)
        
        # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
        service.cleanup()
        
        return result
        
    except Exception as e:
        return {
            "error": f"å¤„ç†æŸ¥è¯¢æ—¶å‡ºé”™: {str(e)}",
            "answer": "",
            "sources": [],
            "sources_count": 0
        }

def main():
    """ä¸»å‡½æ•° - åˆ¤æ–­æ˜¯å¦ä»stdinè¯»å–æ•°æ®è¿˜æ˜¯è¿è¡Œæµ‹è¯•"""
    import select
    
    # æ£€æŸ¥æ˜¯å¦æœ‰stdinè¾“å…¥
    if select.select([sys.stdin], [], [], 0)[0]:
        # æœ‰stdinè¾“å…¥ï¼Œå¤„ç†JSONæŸ¥è¯¢
        result = stdin_handler()
        print(json.dumps(result, ensure_ascii=False, indent=None))
    else:
        # æ²¡æœ‰stdinè¾“å…¥ï¼Œè¿è¡Œæµ‹è¯•
        print("ğŸ§ª æµ‹è¯•ç®€åŒ–ç‰ˆR2 RAGæŸ¥è¯¢æœåŠ¡...")
        
        # åˆ›å»ºæœåŠ¡å®ä¾‹
        service = RAGR2SimpleQueryService()
        
        if not service.is_initialized:
            print(f"âŒ æœåŠ¡åˆå§‹åŒ–å¤±è´¥: {service.initialization_error}")
            return
        
        print("âœ… æœåŠ¡åˆå§‹åŒ–æˆåŠŸï¼")
        
        # æµ‹è¯•æŸ¥è¯¢
        test_query = "å¦‚ä½•è¯†åˆ«çº¦ä¼šä¸­çš„çº¢æ——ä¿¡å·ï¼Ÿ"
        result = service.query(test_query, diagnostic_mode=True)
        
        if result.get("error"):
            print(f"âŒ æŸ¥è¯¢å¤±è´¥: {result['error']}")
        else:
            print(f"âœ… æŸ¥è¯¢æˆåŠŸ!")
            print(f"ğŸ“„ ä½¿ç”¨äº† {result.get('sources_count', 0)} ä¸ªä¸“ä¸šèµ„æ–™")
            print(f"ğŸ’¡ ç­”æ¡ˆé¢„è§ˆ: {result.get('answer', '')[:200]}...")
        
        # æ¸…ç†
        service.cleanup()

if __name__ == "__main__":
    main() 