#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Whisper è¯­éŸ³è½¬å½•æœåŠ¡ - ä½¿ç”¨ Replicate API
æä¾›é«˜è´¨é‡çš„è¯­éŸ³è½¬å½•åŠŸèƒ½
"""

import os
import sys
import json
import logging
from pathlib import Path
from dotenv import load_dotenv
import replicate
import time
from datetime import datetime

# åŠ è½½ç¯å¢ƒå˜é‡
load_dotenv()

# è®¾ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    stream=sys.stderr
)
logger = logging.getLogger(__name__)

class WhisperReplicateService:
    """åŸºäº Replicate API çš„ Whisper è¯­éŸ³è½¬å½•æœåŠ¡"""
    
    def __init__(self):
        self.api_token = os.getenv("REPLICATE_API_TOKEN")
        if not self.api_token:
            raise ValueError("æœªæ‰¾åˆ° REPLICATE_API_TOKEN ç¯å¢ƒå˜é‡ï¼")
        
        # è®¾ç½® Replicate API token
        os.environ["REPLICATE_API_TOKEN"] = self.api_token
        
        # Whisper æ¨¡å‹é…ç½®
        self.model = "openai/whisper:8099696689d249cf8b122d833c36ac3f75505c666a395ca40ef26f68e7d3d16e"
        
        logger.info("ğŸ¤ Whisper Replicate æœåŠ¡åˆå§‹åŒ–æˆåŠŸ")
    
    def transcribe_audio_file(self, audio_file_path: str, language: str = "zh") -> dict:
        """
        è½¬å½•éŸ³é¢‘æ–‡ä»¶
        
        Args:
            audio_file_path: éŸ³é¢‘æ–‡ä»¶è·¯å¾„
            language: è¯­è¨€ä»£ç ï¼Œé»˜è®¤ä¸ºä¸­æ–‡
        
        Returns:
            dict: è½¬å½•ç»“æœ
        """
        try:
            logger.info(f"ğŸ¯ å¼€å§‹è½¬å½•éŸ³é¢‘æ–‡ä»¶: {audio_file_path}")
            
            # éªŒè¯æ–‡ä»¶å­˜åœ¨
            if not os.path.exists(audio_file_path):
                raise FileNotFoundError(f"éŸ³é¢‘æ–‡ä»¶ä¸å­˜åœ¨: {audio_file_path}")
            
            # æ£€æŸ¥æ–‡ä»¶å¤§å°
            file_size = os.path.getsize(audio_file_path)
            logger.info(f"ğŸ“ éŸ³é¢‘æ–‡ä»¶å¤§å°: {file_size / (1024*1024):.2f} MB")
            
            # ä¸Šä¼ æ–‡ä»¶å¹¶è·å– URL
            logger.info("ğŸ“¤ ä¸Šä¼ éŸ³é¢‘æ–‡ä»¶åˆ° Replicate...")
            
            # ä½¿ç”¨ Replicate API è¿›è¡Œè½¬å½•
            start_time = time.time()
            
            with open(audio_file_path, "rb") as audio_file:
                input_data = {
                    "audio": audio_file,
                    "model": "large-v3",  # ä½¿ç”¨æœ€æ–°çš„ large-v3 æ¨¡å‹
                    "language": language,
                    "temperature": 0.0,    # é™ä½éšæœºæ€§ï¼Œæé«˜å‡†ç¡®æ€§
                    "suppress_tokens": "-1",  # ä¸æŠ‘åˆ¶ä»»ä½• token
                    "initial_prompt": "",     # å¯ä»¥æ·»åŠ æç¤ºè¯æ¥æé«˜å‡†ç¡®æ€§
                    "condition_on_previous_text": True,  # åŸºäºå‰æ–‡è¿›è¡Œæ¡ä»¶åŒ–
                    "word_timestamps": True  # å¯ç”¨è¯çº§æ—¶é—´æˆ³
                }
                
                logger.info("ğŸ§  æ­£åœ¨è°ƒç”¨ Replicate Whisper API...")
                output = replicate.run(self.model, input=input_data)
            
            processing_time = time.time() - start_time
            
            # è§£æè¾“å‡ºç»“æœ
            transcription_text = ""
            segments = []
            
            if isinstance(output, dict):
                # è·å–ä¸»è¦è½¬å½•æ–‡æœ¬
                transcription_text = output.get("text", "")
                
                # å¦‚æœä¸»è¦æ–‡æœ¬ä¸ºç©ºï¼Œå°è¯•ä»segmentsä¸­æ‹¼æ¥
                if not transcription_text:
                    segments_data = output.get("segments", [])
                    if segments_data:
                        transcription_text = " ".join([segment.get("text", "").strip() for segment in segments_data])
                
                # è·å–åˆ†æ®µä¿¡æ¯
                segments_data = output.get("segments", [])
                for segment in segments_data:
                    segments.append({
                        "id": segment.get("id", 0),
                        "start": segment.get("start", 0.0),
                        "end": segment.get("end", 0.0),
                        "text": segment.get("text", ""),
                        "tokens": segment.get("tokens", []),
                        "temperature": segment.get("temperature", 0.0),
                        "avg_logprob": segment.get("avg_logprob", 0.0),
                        "compression_ratio": segment.get("compression_ratio", 0.0),
                        "no_speech_prob": segment.get("no_speech_prob", 0.0)
                    })
            elif isinstance(output, str):
                transcription_text = output
            
            # æ„å»ºç»“æœ
            result = {
                "success": True,
                "transcription": transcription_text,
                "language": language,
                "processing_time": processing_time,
                "segments": segments,
                "file_info": {
                    "file_path": audio_file_path,
                    "file_size": file_size,
                    "file_name": os.path.basename(audio_file_path)
                },
                "model_info": {
                    "provider": "Replicate",
                    "model": "openai/whisper:large-v3",
                    "version": "8099696689d249cf8b122d833c36ac3f75505c666a395ca40ef26f68e7d3d16e"
                },
                "timestamp": datetime.now().strftime('%Y-%m-%d %H:%M:%S')
            }
            
            logger.info(f"âœ… è½¬å½•æˆåŠŸå®Œæˆ")
            logger.info(f"ğŸ“ è½¬å½•æ–‡æœ¬é•¿åº¦: {len(transcription_text)} å­—ç¬¦")
            logger.info(f"ğŸ“Š å¤„ç†æ—¶é—´: {processing_time:.2f} ç§’")
            logger.info(f"ğŸ¯ åˆ†æ®µæ•°é‡: {len(segments)}")
            
            return result
            
        except Exception as e:
            logger.error(f"âŒ è½¬å½•å¤±è´¥: {str(e)}")
            return {
                "success": False,
                "error": str(e),
                "error_type": type(e).__name__,
                "file_path": audio_file_path,
                "timestamp": datetime.now().strftime('%Y-%m-%d %H:%M:%S')
            }
    
    def transcribe_from_url(self, audio_url: str, language: str = "zh") -> dict:
        """
        ä» URL è½¬å½•éŸ³é¢‘
        
        Args:
            audio_url: éŸ³é¢‘æ–‡ä»¶ URL
            language: è¯­è¨€ä»£ç 
        
        Returns:
            dict: è½¬å½•ç»“æœ
        """
        try:
            logger.info(f"ğŸ¯ å¼€å§‹ä» URL è½¬å½•éŸ³é¢‘: {audio_url}")
            
            input_data = {
                "audio": audio_url,
                "model": "large-v3",
                "language": language,
                "temperature": 0.0,
                "suppress_tokens": "-1",
                "initial_prompt": "",
                "condition_on_previous_text": True,
                "word_timestamps": True
            }
            
            start_time = time.time()
            logger.info("ğŸ§  æ­£åœ¨è°ƒç”¨ Replicate Whisper API...")
            output = replicate.run(self.model, input=input_data)
            processing_time = time.time() - start_time
            
            # è§£æè¾“å‡ºç»“æœ
            transcription_text = ""
            segments = []
            
            if isinstance(output, dict):
                transcription_text = output.get("text", "")
                
                # å¦‚æœä¸»è¦æ–‡æœ¬ä¸ºç©ºï¼Œå°è¯•ä»segmentsä¸­æ‹¼æ¥
                if not transcription_text:
                    segments_data = output.get("segments", [])
                    if segments_data:
                        transcription_text = " ".join([segment.get("text", "").strip() for segment in segments_data])
                
                segments_data = output.get("segments", [])
                for segment in segments_data:
                    segments.append({
                        "id": segment.get("id", 0),
                        "start": segment.get("start", 0.0),
                        "end": segment.get("end", 0.0),
                        "text": segment.get("text", ""),
                        "tokens": segment.get("tokens", []),
                        "temperature": segment.get("temperature", 0.0),
                        "avg_logprob": segment.get("avg_logprob", 0.0),
                        "compression_ratio": segment.get("compression_ratio", 0.0),
                        "no_speech_prob": segment.get("no_speech_prob", 0.0)
                    })
            elif isinstance(output, str):
                transcription_text = output
            
            result = {
                "success": True,
                "transcription": transcription_text,
                "language": language,
                "processing_time": processing_time,
                "segments": segments,
                "file_info": {
                    "audio_url": audio_url
                },
                "model_info": {
                    "provider": "Replicate",
                    "model": "openai/whisper:large-v3",
                    "version": "8099696689d249cf8b122d833c36ac3f75505c666a395ca40ef26f68e7d3d16e"
                },
                "timestamp": datetime.now().strftime('%Y-%m-%d %H:%M:%S')
            }
            
            logger.info(f"âœ… ä» URL è½¬å½•æˆåŠŸå®Œæˆ")
            logger.info(f"ğŸ“ è½¬å½•æ–‡æœ¬é•¿åº¦: {len(transcription_text)} å­—ç¬¦")
            logger.info(f"ğŸ“Š å¤„ç†æ—¶é—´: {processing_time:.2f} ç§’")
            
            return result
            
        except Exception as e:
            logger.error(f"âŒ URL è½¬å½•å¤±è´¥: {str(e)}")
            return {
                "success": False,
                "error": str(e),
                "error_type": type(e).__name__,
                "audio_url": audio_url,
                "timestamp": datetime.now().strftime('%Y-%m-%d %H:%M:%S')
            }

def main():
    """ä¸»å‡½æ•° - å‘½ä»¤è¡Œè°ƒç”¨æ¥å£"""
    if len(sys.argv) < 2:
        print(json.dumps({
            "success": False,
            "error": "Usage: python whisper_replicate_service.py <audio_file_path> [language]"
        }))
        sys.exit(1)
    
    try:
        audio_file_path = sys.argv[1]
        language = sys.argv[2] if len(sys.argv) > 2 else "zh"
        
        # åˆ›å»ºæœåŠ¡å®ä¾‹
        whisper_service = WhisperReplicateService()
        
        # æ‰§è¡Œè½¬å½•
        result = whisper_service.transcribe_audio_file(audio_file_path, language)
        
        # è¾“å‡ºç»“æœ
        print(json.dumps(result, ensure_ascii=False, indent=2))
        
    except Exception as e:
        error_result = {
            "success": False,
            "error": str(e),
            "error_type": type(e).__name__,
            "timestamp": datetime.now().strftime('%Y-%m-%d %H:%M:%S')
        }
        print(json.dumps(error_result, ensure_ascii=False, indent=2))
        sys.exit(1)

if __name__ == "__main__":
    main() 