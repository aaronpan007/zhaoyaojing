#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
AIæƒ…æ„Ÿå®‰å…¨åŠ©æ‰‹ - RAGæŸ¥è¯¢ç³»ç»Ÿ (Cloudflare R2 + Replicateç‰ˆæœ¬)
æ™ºèƒ½æŸ¥è¯¢R2äº‘å­˜å‚¨çŸ¥è¯†åº“å¹¶è¿”å›ä¸“ä¸šåˆ†æç»“æœ
"""

import os
import sys
from pathlib import Path
import logging
from dotenv import load_dotenv
import json
import replicate
from typing import List, Dict, Any

# LlamaIndexæ ¸å¿ƒæ¨¡å—
from llama_index.core import (
    StorageContext,
    load_index_from_storage,
    Settings
)
from llama_index.core.embeddings import BaseEmbedding

# S3å…¼å®¹å­˜å‚¨æ¨¡å—
from llama_index.storage.kvstore.s3 import S3DBKVStore
from llama_index.storage.docstore.s3 import S3DocumentStore
from llama_index.vector_stores.simple import SimpleVectorStore

# S3FSæ–‡ä»¶ç³»ç»Ÿï¼ˆS3å…¼å®¹ï¼‰
import s3fs

# è®¾ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

class ReplicateEmbedding(BaseEmbedding):
    """
    åŸºäºReplicate APIçš„è‡ªå®šä¹‰embeddingç±»
    ä½¿ç”¨é«˜è´¨é‡çš„BGE embeddingæ¨¡å‹
    """
    
    def __init__(self, model_name: str = "nateraw/bge-large-en-v1.5", **kwargs):
        """
        åˆå§‹åŒ–Replicate Embedding
        
        Args:
            model_name: Replicateä¸Šçš„embeddingæ¨¡å‹åç§°
        """
        super().__init__(**kwargs)
        self.model_name = model_name
        
        # åˆå§‹åŒ–Replicateå®¢æˆ·ç«¯
        load_dotenv()
        self.api_token = os.getenv("REPLICATE_API_TOKEN")
        if not self.api_token:
            raise ValueError("æœªæ‰¾åˆ°REPLICATE_API_TOKENç¯å¢ƒå˜é‡ï¼è¯·åœ¨.envæ–‡ä»¶ä¸­é…ç½®æ‚¨çš„Replicate APIå¯†é’¥")
        
        # é…ç½®replicate
        os.environ["REPLICATE_API_TOKEN"] = self.api_token
        
        logger.debug(f"Replicate Embeddingåˆå§‹åŒ–å®Œæˆï¼Œä½¿ç”¨æ¨¡å‹: {self.model_name}")
    
    def _get_text_embedding(self, text: str) -> List[float]:
        """è·å–å•ä¸ªæ–‡æœ¬çš„embedding"""
        try:
            # è°ƒç”¨Replicate embedding API
            output = replicate.run(
                self.model_name,
                input={"text": text}
            )
            
            # å¤„ç†è¾“å‡ºæ ¼å¼
            if isinstance(output, list) and len(output) > 0:
                if isinstance(output[0], list):
                    # å¦‚æœæ˜¯åµŒå¥—åˆ—è¡¨ï¼Œå–ç¬¬ä¸€ä¸ª
                    embedding = output[0]
                else:
                    # å¦‚æœæ˜¯å•å±‚åˆ—è¡¨
                    embedding = output
            else:
                raise ValueError(f"æ„å¤–çš„embeddingè¾“å‡ºæ ¼å¼: {type(output)}")
            
            # ç¡®ä¿è¿”å›çš„æ˜¯floatåˆ—è¡¨
            return [float(x) for x in embedding]
            
        except Exception as e:
            logger.error(f"Replicate embeddingè°ƒç”¨å¤±è´¥: {str(e)}")
            raise e
    
    def _get_query_embedding(self, query: str) -> List[float]:
        """è·å–æŸ¥è¯¢æ–‡æœ¬çš„embeddingï¼ˆä¸æ–‡æ¡£embeddingç›¸åŒï¼‰"""
        return self._get_text_embedding(query)
    
    def _get_text_embeddings(self, texts: List[str]) -> List[List[float]]:
        """æ‰¹é‡è·å–æ–‡æœ¬embedding"""
        embeddings = []
        for text in texts:
            embedding = self._get_text_embedding(text)
            embeddings.append(embedding)
        return embeddings
    
    async def _aget_query_embedding(self, query: str) -> List[float]:
        """å¼‚æ­¥è·å–æŸ¥è¯¢embedding"""
        return self._get_query_embedding(query)
    
    async def _aget_text_embedding(self, text: str) -> List[float]:
        """å¼‚æ­¥è·å–æ–‡æœ¬embedding"""
        return self._get_text_embedding(text)

class RAGR2ReplicateQueryService:
    """RAGæŸ¥è¯¢æœåŠ¡ç±» - Cloudflare R2 + Replicateç‰ˆæœ¬"""
    
    def __init__(self):
        """
        åˆå§‹åŒ–RAGæŸ¥è¯¢æœåŠ¡ - ä½¿ç”¨Cloudflare R2äº‘å­˜å‚¨å’ŒReplicate embedding
        """
        self.index = None
        self.query_engine = None
        self.s3fs = None
        
        # åˆå§‹åŒ–çŠ¶æ€
        self.is_initialized = False
        self.initialization_error = None
        
        try:
            # éªŒè¯R2é…ç½®
            self._validate_r2_config()
            
            # é…ç½®LlamaIndexè®¾ç½®
            self._setup_llama_index()
            
            # åˆå§‹åŒ–S3FSæ–‡ä»¶ç³»ç»Ÿ
            self._setup_s3fs()
            
            # åŠ è½½ç´¢å¼•
            if self.load_index_from_r2():
                self.is_initialized = True
            else:
                self.initialization_error = "ä»R2åŠ è½½ç´¢å¼•å¤±è´¥"
                
        except Exception as e:
            self.initialization_error = str(e)
            logger.error(f"RAGç³»ç»Ÿåˆå§‹åŒ–å¤±è´¥: {str(e)}")
    
    def _validate_r2_config(self):
        """éªŒè¯Cloudflare R2é…ç½®"""
        required_vars = [
            "CLOUDFLARE_ACCOUNT_ID",
            "R2_ACCESS_KEY_ID", 
            "R2_SECRET_ACCESS_KEY",
            "BUCKET_NAME"
        ]
        
        missing_vars = []
        for var in required_vars:
            if not os.getenv(var):
                missing_vars.append(var)
        
        if missing_vars:
            raise ValueError(f"ç¼ºå°‘å¿…éœ€çš„ç¯å¢ƒå˜é‡: {', '.join(missing_vars)}")
        
        logger.debug("R2é…ç½®éªŒè¯é€šè¿‡")
    
    def _setup_llama_index(self):
        """é…ç½®LlamaIndexå…¨å±€è®¾ç½® - ä½¿ç”¨Replicate"""
        load_dotenv()
        
        # æ£€æŸ¥Replicate APIå¯†é’¥
        api_token = os.getenv("REPLICATE_API_TOKEN")
        if not api_token:
            raise ValueError("æœªæ‰¾åˆ°REPLICATE_API_TOKENç¯å¢ƒå˜é‡ï¼è¯·åœ¨.envæ–‡ä»¶ä¸­é…ç½®æ‚¨çš„Replicate APIå¯†é’¥")
        
        # é…ç½®è‡ªå®šä¹‰Replicate Embeddingæ¨¡å‹
        Settings.embed_model = ReplicateEmbedding(
            model_name="nateraw/bge-large-en-v1.5",  # ä½¿ç”¨é«˜è´¨é‡çš„BGEæ¨¡å‹
            embed_batch_size=1  # Replicate APIé€šå¸¸æ¯æ¬¡å¤„ç†ä¸€ä¸ªæ–‡æœ¬
        )
        
        # ä¸è®¾ç½®LLMï¼Œå› ä¸ºæˆ‘ä»¬åœ¨åç«¯å•ç‹¬å¤„ç†
        Settings.llm = None
        
        logger.debug("LlamaIndexé…ç½®å®Œæˆ (Replicate BGE Embedding)")
    
    def _setup_s3fs(self):
        """åˆå§‹åŒ–S3FSæ–‡ä»¶ç³»ç»Ÿè¿æ¥R2"""
        account_id = os.getenv("CLOUDFLARE_ACCOUNT_ID")
        access_key = os.getenv("R2_ACCESS_KEY_ID")
        secret_key = os.getenv("R2_SECRET_ACCESS_KEY")
        
        # Cloudflare R2çš„endpoint URLæ ¼å¼
        endpoint_url = f"https://{account_id}.r2.cloudflarestorage.com"
        
        try:
            self.s3fs = s3fs.S3FileSystem(
                key=access_key,
                secret=secret_key,
                endpoint_url=endpoint_url,
                use_ssl=True
            )
            
            # æµ‹è¯•è¿æ¥
            bucket_name = os.getenv("BUCKET_NAME")
            if not self.s3fs.exists(bucket_name):
                raise ValueError(f"R2å­˜å‚¨æ¡¶ä¸å­˜åœ¨æˆ–æ— æ³•è®¿é—®: {bucket_name}")
            
            logger.debug(f"S3FSè¿æ¥åˆ°R2æˆåŠŸ: {endpoint_url}")
            
        except Exception as e:
            raise ValueError(f"è¿æ¥Cloudflare R2å¤±è´¥: {str(e)}")
    
    def load_index_from_r2(self):
        """ä»Cloudflare R2åŠ è½½ç´¢å¼•"""
        try:
            bucket_name = os.getenv("BUCKET_NAME")
            
            # æ£€æŸ¥å¿…éœ€çš„ç´¢å¼•æ–‡ä»¶æ˜¯å¦å­˜åœ¨
            required_files = [
                f"{bucket_name}/index_store.json",
                f"{bucket_name}/default__vector_store.json",
                f"{bucket_name}/docstore.json"
            ]
            
            for file_path in required_files:
                if not self.s3fs.exists(file_path):
                    logger.error(f"R2ä¸­æœªæ‰¾åˆ°å¿…éœ€æ–‡ä»¶: {file_path}")
                    return False
            
            logger.info("ğŸ”„ ä»R2åŠ è½½RAGç´¢å¼•...")
            
            try:
                # é…ç½®S3å…¼å®¹çš„å­˜å‚¨ä¸Šä¸‹æ–‡
                account_id = os.getenv("CLOUDFLARE_ACCOUNT_ID")
                access_key = os.getenv("R2_ACCESS_KEY_ID")
                secret_key = os.getenv("R2_SECRET_ACCESS_KEY")
                endpoint_url = f"https://{account_id}.r2.cloudflarestorage.com"
                
                # åˆ›å»ºåŸºäºR2çš„KVå­˜å‚¨
                kv_store = S3DBKVStore(
                    s3_bucket=bucket_name,
                    aws_access_key_id=access_key,
                    aws_secret_access_key=secret_key,
                    aws_endpoint_url=endpoint_url
                )
                
                # åˆ›å»ºåŸºäºR2çš„æ–‡æ¡£å­˜å‚¨
                docstore = S3DocumentStore(
                    s3_bucket=bucket_name,
                    aws_access_key_id=access_key,
                    aws_secret_access_key=secret_key,
                    aws_endpoint_url=endpoint_url
                )
                
                # åˆ›å»ºå­˜å‚¨ä¸Šä¸‹æ–‡
                storage_context = StorageContext.from_defaults(
                    docstore=docstore,
                    index_store=kv_store,
                    vector_store=SimpleVectorStore()  # ä½¿ç”¨ç®€å•å‘é‡å­˜å‚¨
                )
                
                # ä»R2å­˜å‚¨ä¸­åŠ è½½ç´¢å¼•
                self.index = load_index_from_storage(storage_context)
                
                # åˆ›å»ºæŸ¥è¯¢å¼•æ“
                self.query_engine = self.index.as_query_engine(
                    similarity_top_k=5,  # è¿”å›æœ€ç›¸ä¼¼çš„5ä¸ªæ–‡æ¡£ç‰‡æ®µ
                    response_mode="compact"  # ç´§å‡‘æ¨¡å¼å›ç­”
                )
                
                logger.info("âœ… ä»R2æˆåŠŸåŠ è½½RAGç´¢å¼•")
                return True
                
            except Exception as e:
                logger.error(f"ä»R2åŠ è½½ç´¢å¼•å¤±è´¥: {str(e)}")
                return False
            
        except Exception as e:
            logger.error(f"R2ç´¢å¼•åŠ è½½è¿‡ç¨‹å‡ºé”™: {str(e)}")
            return False
    
    def query(self, question: str, context: str = "", diagnostic_mode: bool = False) -> dict:
        """
        æ‰§è¡Œæ™ºèƒ½æŸ¥è¯¢
        
        Args:
            question: æŸ¥è¯¢é—®é¢˜
            context: é¢å¤–ä¸Šä¸‹æ–‡ä¿¡æ¯
            diagnostic_mode: æ˜¯å¦å¯ç”¨è¯Šæ–­æ¨¡å¼ï¼Œè¯¦ç»†æ‰“å°æ£€ç´¢ä¿¡æ¯
            
        Returns:
            åŒ…å«æŸ¥è¯¢ç»“æœçš„å­—å…¸
        """
        if not self.is_initialized:
            return {
                "error": f"RAGç³»ç»Ÿæœªåˆå§‹åŒ–: {self.initialization_error}",
                "answer": "",
                "sources": [],
                "query": question,
                "context": context,
                "sources_count": 0
            }
        
        # æ„å»ºå®Œæ•´æŸ¥è¯¢
        full_query = question
        if context.strip():
            full_query = f"ä¸Šä¸‹æ–‡ä¿¡æ¯: {context.strip()}\n\né—®é¢˜: {question}"
        
        logger.info(f"ğŸ” æ‰§è¡ŒR2æŸ¥è¯¢: {question}")
        
        try:
            # æ‰§è¡ŒæŸ¥è¯¢
            response = self.query_engine.query(full_query)
            
            # æå–æºä¿¡æ¯
            sources = []
            if hasattr(response, 'source_nodes'):
                if diagnostic_mode:
                    logger.info(f"ğŸ” ä»R2æ£€ç´¢åˆ° {len(response.source_nodes)} ä¸ªç›¸å…³æ–‡æ¡£ç‰‡æ®µ:")
                
                for i, node in enumerate(response.source_nodes):
                    similarity_score = getattr(node, 'score', 0.0)
                    
                    # è·å–å…ƒæ•°æ®
                    metadata = getattr(node.node, 'metadata', {})
                    file_name = metadata.get('file_name', 'unknown')
                    file_path = metadata.get('file_path', '')
                    
                    # æˆªæ–­æ–‡æœ¬å†…å®¹è¿›è¡Œé¢„è§ˆ
                    text_preview = node.node.text[:200] + "..." if len(node.node.text) > 200 else node.node.text
                    
                    source_info = {
                        "file_name": file_name,
                        "file_path": file_path,
                        "similarity_score": round(similarity_score, 3),
                        "text_preview": text_preview,
                        "node_id": node.node.node_id
                    }
                    
                    sources.append(source_info)
                    
                    if diagnostic_mode:
                        logger.info(f"  ğŸ“„ R2ç‰‡æ®µ {i+1}: {file_name}")
                        logger.info(f"     ç›¸ä¼¼åº¦: {similarity_score:.3f}")
                        logger.info(f"     é¢„è§ˆ: {text_preview[:100]}...")
                        logger.info("")
            
            if diagnostic_mode:
                logger.info(f"ğŸ¯ R2 RAGç³»ç»Ÿè¿”å›ç­”æ¡ˆ:")
                logger.info(f"   æŸ¥è¯¢: {question}")
                logger.info(f"   ç­”æ¡ˆ: {str(response)[:200]}...")
                logger.info(f"   ä½¿ç”¨R2æºæ•°é‡: {len(sources)}")
                logger.info("=" * 50)
            
            return {
                "answer": str(response),
                "sources": sources,
                "query": question,
                "context": context,
                "sources_count": len(sources),
                "storage_type": "cloudflare_r2_replicate"
            }
            
        except Exception as e:
            logger.error(f"R2 RAGæŸ¥è¯¢å¤±è´¥: {str(e)}")
            return {
                "error": f"æŸ¥è¯¢å¤±è´¥: {str(e)}",
                "answer": "",
                "sources": [],
                "query": question,
                "context": context,
                "sources_count": 0
            }

def create_rag_query(user_input: dict, image_analysis: list) -> str:
    """æ ¹æ®ç”¨æˆ·è¾“å…¥å’Œå›¾ç‰‡åˆ†æç»“æœåˆ›å»ºRAGæŸ¥è¯¢å­—ç¬¦ä¸²"""
    query_parts = []
    
    if user_input.get('nickname'):
        query_parts.append(f"åˆ†æå¯¹è±¡æ˜µç§°: {user_input['nickname']}")
    
    if user_input.get('profession'):
        query_parts.append(f"èŒä¸š: {user_input['profession']}")
    
    if user_input.get('age'):
        query_parts.append(f"å¹´é¾„: {user_input['age']}")
    
    if user_input.get('bioOrChatHistory'):
        query_parts.append(f"ä¸ªäººç®€ä»‹æˆ–èŠå¤©è®°å½•: {user_input['bioOrChatHistory']}")
    
    if image_analysis:
        query_parts.append("å›¾ç‰‡åˆ†æç»“æœ:")
        for i, analysis in enumerate(image_analysis):
            query_parts.append(f"å›¾ç‰‡{i+1}: {analysis.get('analysis', '')}")
    
    return " ".join(query_parts)

def generate_final_report(rag_result: dict, user_input: dict, image_analysis: list) -> dict:
    """åŸºäºRAGæŸ¥è¯¢ç»“æœç”Ÿæˆæœ€ç»ˆåˆ†ææŠ¥å‘Š"""
    try:
        # åŸºç¡€æŠ¥å‘Šç»“æ„
        report = {
            "risk_level": "unknown",
            "key_findings": {},
            "final_suggestion": "",
            "confidence_level": "medium",
            "professional_insight": "",
            "analysis_metadata": {
                "processed_images": len(image_analysis),
                "analysis_timestamp": "",
                "processing_time": "",
                "rag_sources_count": rag_result.get("sources_count", 0),
                "storage_type": rag_result.get("storage_type", "cloudflare_r2_replicate")
            }
        }
        
        # å¦‚æœRAGæŸ¥è¯¢æˆåŠŸï¼Œä½¿ç”¨è¿”å›çš„åˆ†æ
        if rag_result.get("answer") and not rag_result.get("error"):
            # ç®€å•çš„é£é™©ç­‰çº§åˆ¤æ–­é€»è¾‘
            answer_text = rag_result["answer"].lower()
            
            if any(word in answer_text for word in ["é«˜é£é™©", "å±é™©", "è­¦å‘Š", "ä¸å»ºè®®"]):
                report["risk_level"] = "high"
            elif any(word in answer_text for word in ["ä¸­ç­‰é£é™©", "è°¨æ…", "æ³¨æ„"]):
                report["risk_level"] = "medium"
            elif any(word in answer_text for word in ["ä½é£é™©", "å®‰å…¨", "å¯ä»¥"]):
                report["risk_level"] = "low"
            else:
                report["risk_level"] = "medium"
            
            # è®¾ç½®ä¸»è¦å‘ç°å’Œå»ºè®®
            report["professional_insight"] = rag_result["answer"]
            report["final_suggestion"] = "åŸºäºR2äº‘å­˜å‚¨ä¸“ä¸šçŸ¥è¯†åº“åˆ†æï¼Œè¯·å‚è€ƒä¸Šè¿°è¯¦ç»†åˆ†æã€‚"
            
            # è®¾ç½®å…³é”®å‘ç°
            if rag_result.get("sources"):
                report["key_findings"]["knowledge_sources"] = f"ä»R2å¼•ç”¨äº†{len(rag_result['sources'])}ä¸ªä¸“ä¸šèµ„æ–™"
            
        else:
            # RAGæŸ¥è¯¢å¤±è´¥çš„åå¤‡æ–¹æ¡ˆ
            report["professional_insight"] = "ç”±äºR2çŸ¥è¯†åº“æŸ¥è¯¢å¤±è´¥ï¼Œæ— æ³•æä¾›ä¸“ä¸šåˆ†æã€‚å»ºè®®æ‰‹åŠ¨è¯„ä¼°ã€‚"
            report["final_suggestion"] = "å»ºè®®å¯»æ±‚ä¸“ä¸šäººå£«æ„è§ã€‚"
            report["risk_level"] = "unknown"
        
        return report
        
    except Exception as e:
        logger.error(f"ç”Ÿæˆæœ€ç»ˆæŠ¥å‘Šå¤±è´¥: {str(e)}")
        return {
            "risk_level": "unknown",
            "key_findings": {"error": "æŠ¥å‘Šç”Ÿæˆå¤±è´¥"},
            "final_suggestion": "ç³»ç»Ÿå‡ºé”™ï¼Œè¯·ç¨åé‡è¯•ã€‚",
            "confidence_level": "low",
            "professional_insight": f"æŠ¥å‘Šç”Ÿæˆå‡ºé”™: {str(e)}",
            "analysis_metadata": {
                "processed_images": len(image_analysis),
                "analysis_timestamp": "",
                "processing_time": "",
                "error": str(e)
            }
        }

def main():
    """æµ‹è¯•å‡½æ•°"""
    print("ğŸ§ª æµ‹è¯•RAG R2 + ReplicateæŸ¥è¯¢æœåŠ¡...")
    
    # åˆ›å»ºæœåŠ¡å®ä¾‹
    service = RAGR2ReplicateQueryService()
    
    if not service.is_initialized:
        print(f"âŒ æœåŠ¡åˆå§‹åŒ–å¤±è´¥: {service.initialization_error}")
        return
    
    print("âœ… æœåŠ¡åˆå§‹åŒ–æˆåŠŸï¼")
    
    # æµ‹è¯•æŸ¥è¯¢
    test_query = "å¦‚ä½•è¯†åˆ«çº¦ä¼šä¸­çš„çº¢æ——ä¿¡å·ï¼Ÿ"
    result = service.query(test_query, diagnostic_mode=True)
    
    print(f"ğŸ¯ æŸ¥è¯¢ç»“æœ: {result}")

if __name__ == "__main__":
    main() 